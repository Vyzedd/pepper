{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "executionInfo": {
     "elapsed": 8580,
     "status": "ok",
     "timestamp": 1717284141542,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "KUA2iplpyAro"
   },
   "source": [
    "first time in a new instance: need to install the following\n",
    "!pip install -U boto3\n",
    "!pip install -U s3fs \n",
    "!conda install geopandas --yes\n",
    "!conda install -c conda-forge netCDF4 gdal --yes\n",
    "\n",
    "# running the two pip installs separately seems to work better somehow... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1717284132963,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "7vg9yCsgxlg2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from time import time\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# import geopandas as gpd\n",
    "from osgeo import osr, gdal\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "# set up s3 location\n",
    "s3 = boto3.client('s3', region_name='us-east-1')  # Replace 'us-west-2' with your AWS region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# some tests. keeping them for demo. skip when running jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-16 16:46:49 2693605824 2020-01_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-01_part2.nc\n",
      "2024-06-16 16:46:49 2519825280 2020-02_part1.nc\n",
      "2024-06-16 16:46:49 1469901152 2020-02_part2.nc\n",
      "2024-06-16 16:46:49 2693605824 2020-03_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-03_part2.nc\n",
      "2024-06-16 16:46:49 2606715548 2020-04_part1.nc\n",
      "2024-06-16 16:46:49 1520587188 2020-04_part2.nc\n",
      "2024-06-16 16:46:49 2693605820 2020-05_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-05_part2.nc\n",
      "2024-06-16 16:46:49 2606715552 2020-06_part1.nc\n",
      "2024-06-16 16:46:49 1520587188 2020-06_part2.nc\n",
      "2024-06-16 16:46:49 2693605824 2020-07_part1.nc\n",
      "2024-06-16 16:46:49 1571273216 2020-07_part2.nc\n",
      "2024-06-16 16:46:49 2693605820 2020-08_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-08_part2.nc\n",
      "2024-06-16 16:46:49 2606715552 2020-09_part1.nc\n",
      "2024-06-16 16:46:49 1520587188 2020-09_part2.nc\n",
      "2024-06-16 16:46:49 2693605820 2020-10_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-10_part2.nc\n",
      "2024-06-16 16:46:49 2606715552 2020-11_part1.nc\n",
      "2024-06-16 16:46:49 1520587184 2020-11_part2.nc\n",
      "2024-06-16 16:46:49 2693605824 2020-12_part1.nc\n",
      "2024-06-16 16:46:49 1571273216 2020-12_part2.nc\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://pepper-dataset/era5-unzipped/2020/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/fsspec/registry.py:275: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 21)\n"
     ]
    }
   ],
   "source": [
    "test_uri = 's3://pepper-dataset/crop_data/crop_IOWA/Iowa_corn_2019.csv'\n",
    "df = pd.read_csv(test_uri)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /vsis3/pepper-dataset/county_mask_data/mask_2/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /vsis3/pepper-dataset/county_mask_data/mask_2/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7fe86d554ea0> >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdal.Open('/vsis3/pepper-dataset/county_mask_data/mask_2/Illinois_Carroll.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/vsis3/pepper-dataset/Temp/2000/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/vsis3/pepper-dataset/Temp/2000/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ds\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2521\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2158\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/vsis3/pepper-dataset/Temp/2000/'"
     ]
    }
   ],
   "source": [
    "with nc.Dataset('/vsis3/pepper-dataset/Temp/2000/', 'r') as ds:\n",
    "    print(ds.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\n",
      "context: <?xml^ version=\"1.0\" encoding=\"UTF-8\"?><Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>8SFKRP8FGXKCES7B</RequestId><HostId>5TwDw6ZmgfN7FMC7Pevatb6/OGjCfMjfRJqMKNrTjwLvZp3/rljsxx/6+eC/1e4K10scL2O5C5Q=</HostId></Error>\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -78] NetCDF: Authorization failure: 's3://pepper-dataset/Temp/2000/2000-06_part1.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://pepper-dataset/Temp/2000/2000-06_part1.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ds\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2521\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2158\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -78] NetCDF: Authorization failure: 's3://pepper-dataset/Temp/2000/2000-06_part1.nc'"
     ]
    }
   ],
   "source": [
    "with nc.Dataset('s3://pepper-dataset/Temp/2000/2000-06_part1.nc', 'r') as ds:\n",
    "    print(ds.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gds = gdal.Open('/vsis3/pepper-dataset/Temp/2000/2000-06_part1.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NETCDF:\"/vsis3/pepper-dataset/Temp/2000/2000-06_part1.nc\":t2m', '[720x251x601] t2m (16-bit integer)'), ('NETCDF:\"/vsis3/pepper-dataset/Temp/2000/2000-06_part1.nc\":evabs', '[720x251x601] evabs (16-bit integer)')]\n",
      "['t2m', 'evabs', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n"
     ]
    }
   ],
   "source": [
    "era_subsets = gds.GetSubDatasets()\n",
    "print(era_subsets[:2])\n",
    "varnames = [x[0].split(':')[-1] for x in era_subsets]\n",
    "print(varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gds1 = gdal.Open(era_subsets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testarr = gds1.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF:\"/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\":t2m\n",
      "t2m\n"
     ]
    }
   ],
   "source": [
    "desc = gds1.GetDescription()\n",
    "print(desc)\n",
    "print(desc.split(':')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gds1_meta = gds1.GetMetadata()\n",
    "gds1_meta.keys()\n",
    "time_set = eval(gds1_meta['NETCDF_DIM_time_VALUES'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(time_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_list = []\n",
    "for t1 in time_set:\n",
    "    t2 = dt.datetime(1900,1,1) + dt.timedelta(hours = int(t1))\n",
    "    time_list.append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 251, 601)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testarr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# prepare masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flist_raw = !aws s3 ls s3://pepper-dataset/county_mask_data/mask_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "# 所有mask文件\n",
    "pad = '2024-06-16 02:14:19      23897 '\n",
    "len(pad)\n",
    "mask_list = []\n",
    "for f in flist_raw:\n",
    "    if \"tif\" in f:\n",
    "        fname = f[31:]\n",
    "        fpath = f\"/vsis3/pepper-dataset/county_mask_data/mask_2/{fname}\"\n",
    "        mask_list.append(fpath)\n",
    "mask_list.sort()\n",
    "print(len(mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 40607,
     "status": "ok",
     "timestamp": 1717284184051,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "p1dUPA7ayICS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 遍历所有 mask 文件，获取某个county的这个变量的数据\n",
    "mask_dict = {}\n",
    "for mask_file in mask_list:\n",
    "    fname = os.path.basename(mask_file)\n",
    "    location = fname.split('.')[0]\n",
    "    mask_dict[location] = {}\n",
    "    # read mask tiff\n",
    "    gd = gdal.Open(mask_file)\n",
    "    garr = gd.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "    mask_dict[location] = garr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Do masking with gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_time(gds_subset):\n",
    "    gds = gdal.Open(gds_subset)\n",
    "    gds_meta = gds.GetMetadata()\n",
    "    time_set = eval(gds_meta['NETCDF_DIM_time_VALUES'])\n",
    "    time_list = []\n",
    "    for t1 in time_set:\n",
    "        t2 = dt.datetime(1900,1,1) + dt.timedelta(hours = int(t1))\n",
    "        time_list.append(t2)\n",
    "    del gds\n",
    "    return time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289764,
     "status": "ok",
     "timestamp": 1717298058303,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "fPILcGAzyUFS",
    "outputId": "1c16eb47-e66e-4cdb-faf3-4feb16fabd5c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving:  time\n",
      "saving:  Iowa_Adair\n",
      "saving:  Iowa_Adams\n",
      "saving:  Iowa_Allamakee\n",
      "saving:  Iowa_Appanoose\n",
      "saving:  Iowa_Audubon\n",
      "saving:  Iowa_Benton\n",
      "saving:  Iowa_Black Hawk\n",
      "saving:  Iowa_Boone\n",
      "saving:  Iowa_Bremer\n",
      "saving:  Iowa_Buchanan\n",
      "saving:  Iowa_Buena Vista\n",
      "saving:  Iowa_Butler\n",
      "saving:  Iowa_Calhoun\n",
      "saving:  Iowa_Carroll\n",
      "saving:  Iowa_Cass\n",
      "saving:  Iowa_Cedar\n",
      "saving:  Iowa_Cerro Gordo\n",
      "saving:  Iowa_Cherokee\n",
      "saving:  Iowa_Chickasaw\n",
      "saving:  Iowa_Clarke\n",
      "saving:  Iowa_Clay\n",
      "saving:  Iowa_Clayton\n",
      "saving:  Iowa_Clinton\n",
      "saving:  Iowa_Crawford\n",
      "saving:  Iowa_Dallas\n",
      "saving:  Iowa_Davis\n",
      "saving:  Iowa_Decatur\n",
      "saving:  Iowa_Delaware\n",
      "saving:  Iowa_Des Moines\n",
      "saving:  Iowa_Dickinson\n",
      "saving:  Iowa_Dubuque\n",
      "saving:  Iowa_Emmet\n",
      "saving:  Iowa_Fayette\n",
      "saving:  Iowa_Floyd\n",
      "saving:  Iowa_Franklin\n",
      "saving:  Iowa_Fremont\n",
      "saving:  Iowa_Greene\n",
      "saving:  Iowa_Grundy\n",
      "saving:  Iowa_Guthrie\n",
      "saving:  Iowa_Hamilton\n",
      "saving:  Iowa_Hancock\n",
      "saving:  Iowa_Hardin\n",
      "saving:  Iowa_Harrison\n",
      "saving:  Iowa_Henry\n",
      "saving:  Iowa_Howard\n",
      "saving:  Iowa_Humboldt\n",
      "saving:  Iowa_Ida\n",
      "saving:  Iowa_Iowa\n",
      "saving:  Iowa_Jackson\n",
      "saving:  Iowa_Jasper\n",
      "saving:  Iowa_Jefferson\n",
      "saving:  Iowa_Johnson\n",
      "saving:  Iowa_Jones\n",
      "saving:  Iowa_Keokuk\n",
      "saving:  Iowa_Kossuth\n",
      "saving:  Iowa_Lee\n",
      "saving:  Iowa_Linn\n",
      "saving:  Iowa_Louisa\n",
      "saving:  Iowa_Lucas\n",
      "saving:  Iowa_Lyon\n",
      "saving:  Iowa_Madison\n",
      "saving:  Iowa_Mahaska\n",
      "saving:  Iowa_Marion\n",
      "saving:  Iowa_Marshall\n",
      "saving:  Iowa_Mills\n",
      "saving:  Iowa_Mitchell\n",
      "saving:  Iowa_Monona\n",
      "saving:  Iowa_Monroe\n",
      "saving:  Iowa_Montgomery\n",
      "saving:  Iowa_Muscatine\n",
      "saving:  Iowa_O_Brien\n",
      "saving:  Iowa_Osceola\n",
      "saving:  Iowa_Page\n",
      "saving:  Iowa_Palo Alto\n",
      "saving:  Iowa_Plymouth\n",
      "saving:  Iowa_Pocahontas\n",
      "saving:  Iowa_Polk\n",
      "saving:  Iowa_Pottawattamie\n",
      "saving:  Iowa_Poweshiek\n",
      "saving:  Iowa_Ringgold\n",
      "saving:  Iowa_Sac\n",
      "saving:  Iowa_Scott\n",
      "saving:  Iowa_Shelby\n",
      "saving:  Iowa_Sioux\n",
      "saving:  Iowa_Story\n",
      "saving:  Iowa_Tama\n",
      "saving:  Iowa_Taylor\n",
      "saving:  Iowa_Union\n",
      "saving:  Iowa_Van Buren\n",
      "saving:  Iowa_Wapello\n",
      "saving:  Iowa_Warren\n",
      "saving:  Iowa_Washington\n",
      "saving:  Iowa_Wayne\n",
      "saving:  Iowa_Webster\n",
      "saving:  Iowa_Winnebago\n",
      "saving:  Iowa_Winneshiek\n",
      "saving:  Iowa_Woodbury\n",
      "saving:  Iowa_Worth\n",
      "saving:  Iowa_Wright\n"
     ]
    }
   ],
   "source": [
    "geotrans = [-125.05, 0.1, 0, 50.05, 0, -0.1]\n",
    "vlist2 = ['evabs', 'evavt', 'sp', 'sshf', 'ssrd', 'strd', 'tp']\n",
    "vlist1 = ['t2m', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n",
    "\n",
    "with open('./mask_log_updated_Iowa.log','a') as fp:\n",
    "    fp.writelines('='*10+'\\n')\n",
    "\n",
    "for year in range(2000, 2001):\n",
    "    # 获取某一年的文件\n",
    "    year_path = eval(\"f's3://pepper-dataset/Temp/{year}/'\")\n",
    "    flist_raw = !aws s3 ls $year_path\n",
    "    flist = []\n",
    "    for f in flist_raw:\n",
    "        f2 = f.split(' ')[-1]\n",
    "        if '.nc' not in f2:\n",
    "            continue\n",
    "        f3 = f'/vsis3/pepper-dataset/Temp/{year}/{f2}'\n",
    "        flist.append(f3)\n",
    "    flist.sort()\n",
    "\n",
    "    # 遍历该年的所有netcdf文件， 确定是part1还是part2\n",
    "    for ncf in flist:\n",
    "        ncfname = os.path.basename(ncf)\n",
    "        yearmonth = ncfname.split('_')[0]\n",
    "        month_int = int(yearmonth.split('-')[1])\n",
    "\n",
    "        # 跳过已经完成的部分\n",
    "        # if year == 2020:\n",
    "        #     if month_int not in [9, 10]:\n",
    "        #         continue\n",
    "        # 所有county数据保存在 2 个大表里\n",
    "        # 每个大表都有一个 time 列表，然后每个 county 单独一个 dict\n",
    "        outd = {'time': []}\n",
    "        # read basic variables\n",
    "        gds = gdal.Open(ncf) \n",
    "        gds_subsets = gds.GetSubDatasets()\n",
    "        var_dict = {}\n",
    "        var_all = []\n",
    "        for gds_ss in gds_subsets:\n",
    "            v = gds_ss[0].split(':')[-1]\n",
    "            var_all.append(v)\n",
    "            var_dict[v] = gds_ss[0]\n",
    "\n",
    "        # set variable list \n",
    "        if ncf.split('_')[-1] == 'part1.nc':\n",
    "            vlist = vlist1\n",
    "        elif ncf.split('_')[-1] == 'part2.nc':\n",
    "            vlist = vlist2\n",
    "        else:\n",
    "            raise ValueError('Unknown file type')\n",
    "\n",
    "        # 打开netcdf文件，先获取时间信息\n",
    "        timelist = get_time(var_dict[var_all[0]])\n",
    "        outd['time'].extend(timelist)\n",
    "\n",
    "        # 遍历所有变量名，获取全美的数据\n",
    "        for v in vlist:\n",
    "            with open('./mask_log_updated_Iowa.log','a') as fp:\n",
    "                now_str = dt.datetime.strftime(dt.datetime.now(), '%Y%m%dT%H%M%S')\n",
    "                fp.writelines(f'{ncf} - {v} - {now_str}\\n')\n",
    "\n",
    "            gds = gdal.Open(var_dict[v])\n",
    "            gds_band = gds.GetRasterBand(1)\n",
    "            nodata = gds_band.GetNoDataValue()\n",
    "            arr1 = gds.ReadAsArray().astype(np.float32)\n",
    "            arr = np.where(arr1 < -30000, np.nan, arr1)\n",
    "            # arr = ds.variables[v][:]   # [time, lat, lon]\n",
    "            # arr2 = cp.asarray(arr1.data)\n",
    "            # arr = cp.where(arr2 < -30000, cp.nan, arr2)\n",
    "\n",
    "            for location in mask_dict.keys():\n",
    "                print(ncf)\n",
    "                print(v)\n",
    "                print(location)\n",
    "                if location not in outd.keys():\n",
    "                    outd[location] = {}\n",
    "                if v not in outd[location].keys():\n",
    "                    outd[location][v] = np.array([])\n",
    "                garr1 = mask_dict[location]\n",
    "                garr_inds = np.where(garr1 > -10)\n",
    "                # arr_masked = garr1 * arr\n",
    "                arr_masked = arr[:, garr_inds[0], garr_inds[1]]\n",
    "                arr_out = np.nanmean(arr_masked, axis=1)\n",
    "                # arr_out = cp.nanmean(arr_masked, axis=(1,2))\n",
    "                # print('einsum')\n",
    "                # arr_out = np.einsum(\"ijk,jk->ijk\", arr, garr)\n",
    "                # arr_out = np.einsum(\"ijk->i\", arr_masked)\n",
    "                print('saving to outd (dictionary)')\n",
    "                outd[location][v] = np.concatenate(\n",
    "                    [outd[location][v], arr_out],\n",
    "                    axis=0\n",
    "                    )\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        # 每个月保存一次\n",
    "        partname = ncfname.split('_')[1].split('.')[0]\n",
    "        errlist = []\n",
    "        for location in outd.keys():\n",
    "            print('saving: ', location)\n",
    "            if location == 'time':\n",
    "                continue\n",
    "            os.makedirs(f'/home/ec2-user/SageMaker/pepper/county_env3/{location}', exist_ok=True)\n",
    "            try:\n",
    "                outd1 = {}\n",
    "                for key in outd[location].keys():\n",
    "                    outd1[key] = outd[location][key]# .get()\n",
    "                t2 = pd.DataFrame(outd1)\n",
    "                t2['datetime'] = outd['time']\n",
    "                t2.to_csv(\n",
    "                    f'/home/ec2-user/SageMaker/pepper/county_env3/{location}/try5_{location}_{yearmonth}_{partname}.csv', \n",
    "                    index=False\n",
    "                )\n",
    "            except:\n",
    "                print(f'error with location: {location}')\n",
    "                errlist.append(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NETCDF:\"/vsis3/pepper-dataset/Temp/2000/2000-02_part1.nc\":swvl1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_dict[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds_band.YSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Int16'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdal.GetDataTypeName(gds_band.DataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5859.6875, 5861.8125, 5861.8125, 5861.625 , 5861.5625, 5861.5625,\n",
       "       5861.5625, 5861.5625, 5861.5625, 5861.4375, 5861.4375, 5861.4375,\n",
       "       5861.4375, 5861.4375, 5861.375 , 5861.375 , 5861.375 , 5861.3125,\n",
       "       5861.1875, 5861.    , 5860.8125, 5860.5   , 5860.25  , 5860.    ,\n",
       "       5859.8125, 5861.9375, 5861.8125, 5861.8125, 5861.8125, 5861.625 ,\n",
       "       5861.5625, 5861.5625, 5861.5625, 5861.5625, 5861.5625, 5861.5625,\n",
       "       5861.5625, 5861.5625, 5861.5625, 5861.5625, 5861.5625, 5861.5625,\n",
       "       5861.375 , 5860.9375, 5860.375 , 5859.9375, 5859.625 , 5859.375 ,\n",
       "       5859.125 , 5861.8125, 5861.625 , 5861.5625, 5861.5   , 5861.5   ,\n",
       "       5861.5   , 5861.5   , 5861.5   , 5861.4375, 5861.4375, 5861.4375,\n",
       "       5861.3125, 5861.125 , 5860.875 , 5860.6875, 5860.3125, 5859.625 ,\n",
       "       5859.    , 5858.25  , 5857.375 , 5856.375 , 5855.375 , 5854.5625,\n",
       "       5854.0625, 5861.5625, 5861.375 , 5861.3125, 5861.    , 5860.8125,\n",
       "       5860.6875, 5860.375 , 5860.1875, 5859.9375, 5859.6875, 5859.5   ,\n",
       "       5859.4375, 5859.25  , 5859.0625, 5859.    , 5858.75  , 5858.4375,\n",
       "       5858.0625, 5857.8125, 5857.4375, 5857.0625, 5856.75  , 5856.375 ,\n",
       "       5856.1875, 5861.875 , 5861.75  , 5861.5625, 5861.5625, 5861.4375,\n",
       "       5861.4375, 5861.4375, 5861.375 , 5861.375 , 5861.3125, 5861.3125,\n",
       "       5861.3125, 5861.3125, 5861.3125, 5861.3125, 5861.3125, 5861.3125,\n",
       "       5861.3125, 5861.0625, 5860.875 , 5860.5625, 5860.1875, 5859.9375,\n",
       "       5859.75  , 5861.8125, 5861.5625, 5861.4375, 5861.375 , 5861.3125,\n",
       "       5861.3125, 5861.1875, 5861.1875, 5861.0625, 5861.0625, 5861.    ,\n",
       "       5860.9375, 5860.875 , 5860.8125, 5860.6875, 5860.6875, 5860.4375,\n",
       "       5860.1875, 5859.9375, 5859.6875, 5859.5   , 5859.3125, 5859.125 ,\n",
       "       5859.    , 5861.9375, 5861.8125, 5861.8125, 5861.625 , 5861.5625,\n",
       "       5861.5625, 5861.5625, 5861.5625, 5861.5625, 5861.5625, 5861.5625,\n",
       "       5861.5625, 5861.5625, 5861.5625, 5861.5625, 5861.5625, 5861.4375,\n",
       "       5861.3125, 5861.    , 5860.8125, 5860.4375, 5860.1875, 5859.9375,\n",
       "       5859.6875, 5861.8125, 5861.625 , 5861.5625, 5861.5625, 5861.5625,\n",
       "       5861.5   , 5861.4375, 5861.4375, 5861.5625, 5861.5625, 5861.5625,\n",
       "       5861.5625, 5861.5625, 5861.5625, 5861.625 , 5861.75  , 5861.625 ,\n",
       "       5861.4375, 5861.1875, 5860.8125, 5860.375 , 5860.    , 5859.6875,\n",
       "       5859.5   , 5861.8125, 5861.625 , 5861.5625, 5861.5625, 5861.5625,\n",
       "       5861.5625, 5861.625 , 5861.8125, 5861.8125, 5861.8125, 5861.8125,\n",
       "       5861.8125, 5861.8125, 5861.8125, 5861.8125, 5861.8125, 5861.8125,\n",
       "       5861.8125, 5861.8125, 5861.8125, 5861.8125, 5861.8125, 5861.8125,\n",
       "       5861.875 , 5862.    , 5862.0625, 5862.1875, 5862.1875, 5862.1875,\n",
       "       5862.1875, 5862.3125, 5862.375 , 5862.375 , 5862.375 , 5862.375 ,\n",
       "       5862.375 , 5862.375 , 5862.375 , 5862.4375, 5862.5   , 5862.4375,\n",
       "       5862.4375, 5862.1875, 5862.    , 5861.75  , 5861.375 , 5860.875 ,\n",
       "       5860.5625, 5861.6875, 5861.4375, 5861.3125, 5860.875 , 5860.6875,\n",
       "       5860.375 , 5860.25  , 5860.    , 5859.6875, 5859.5   , 5859.3125,\n",
       "       5859.125 , 5859.    , 5858.75  , 5858.625 , 5858.375 , 5858.125 ,\n",
       "       5857.9375, 5857.5625, 5857.3125, 5857.    , 5856.6875, 5856.375 ,\n",
       "       5856.0625, 5861.8125, 5861.5625, 5861.375 , 5861.3125, 5861.0625,\n",
       "       5860.875 , 5860.8125, 5860.6875, 5860.5625, 5860.375 , 5860.375 ,\n",
       "       5860.3125, 5860.25  , 5860.125 , 5860.125 , 5860.125 , 5860.0625,\n",
       "       5859.8125, 5859.5   , 5859.0625, 5858.75  , 5858.3125, 5858.0625,\n",
       "       5858.    , 5861.875 , 5861.8125, 5861.8125, 5861.8125, 5861.8125,\n",
       "       5861.75  , 5861.6875, 5861.6875, 5861.5625, 5861.5625, 5861.5625,\n",
       "       5861.5625, 5861.5   , 5861.375 , 5861.375 , 5861.1875, 5860.9375,\n",
       "       5860.6875, 5860.25  , 5859.875 , 5859.5   , 5859.0625, 5858.75  ,\n",
       "       5858.5   , 5861.875 , 5861.8125, 5861.5625, 5861.5625, 5861.4375,\n",
       "       5861.4375, 5861.375 , 5861.375 , 5861.3125, 5861.3125, 5861.3125,\n",
       "       5861.3125, 5861.1875, 5861.1875, 5861.1875, 5861.1875, 5861.1875,\n",
       "       5861.1875, 5861.0625, 5860.875 , 5860.625 , 5860.3125, 5859.9375,\n",
       "       5859.6875, 5861.8125, 5861.625 , 5861.5625, 5861.5   , 5861.4375,\n",
       "       5861.4375, 5861.4375, 5861.4375, 5861.375 , 5861.375 , 5861.3125,\n",
       "       5861.1875, 5861.1875, 5861.1875, 5861.3125, 5861.1875, 5861.1875,\n",
       "       5861.1875, 5861.3125, 5861.375 , 5861.375 , 5861.375 , 5861.375 ,\n",
       "       5861.1875, 5861.5625, 5861.3125, 5860.875 , 5860.6875, 5860.375 ,\n",
       "       5860.25  , 5860.125 , 5859.9375, 5859.875 , 5859.6875, 5859.6875,\n",
       "       5859.625 , 5859.5   , 5859.4375, 5859.375 , 5859.375 , 5859.3125,\n",
       "       5859.3125, 5859.3125, 5859.3125, 5859.25  , 5859.125 , 5859.125 ,\n",
       "       5859.0625, 5861.8125, 5861.5625, 5861.375 , 5861.3125, 5861.125 ,\n",
       "       5861.    , 5860.9375, 5860.8125, 5860.8125, 5860.6875, 5860.6875,\n",
       "       5860.5   , 5860.375 , 5860.3125, 5860.1875, 5860.125 , 5859.875 ,\n",
       "       5859.6875, 5859.3125, 5859.    , 5858.75  , 5858.5   , 5858.25  ,\n",
       "       5858.125 , 5861.875 , 5861.8125, 5861.5625, 5861.4375, 5861.375 ,\n",
       "       5861.375 , 5861.3125, 5861.0625, 5861.    , 5861.    , 5860.875 ,\n",
       "       5860.8125, 5860.8125, 5860.6875, 5860.6875, 5860.5625, 5860.375 ,\n",
       "       5860.25  , 5860.    , 5859.6875, 5859.4375, 5859.0625, 5858.75  ,\n",
       "       5858.4375, 5861.875 , 5861.8125, 5861.8125, 5861.625 , 5861.5625,\n",
       "       5861.5625, 5861.5625, 5861.5625, 5861.4375, 5861.375 , 5861.375 ,\n",
       "       5861.3125, 5861.3125, 5861.125 , 5861.0625, 5861.0625, 5861.0625,\n",
       "       5861.0625, 5861.    , 5860.8125, 5860.5   , 5860.25  , 5859.9375,\n",
       "       5859.6875, 5862.    , 5861.875 , 5861.875 , 5861.8125, 5861.8125,\n",
       "       5861.625 , 5861.5625, 5861.5625, 5861.4375, 5861.4375, 5861.375 ,\n",
       "       5861.375 , 5861.3125, 5861.3125, 5861.3125, 5861.375 , 5861.375 ,\n",
       "       5861.375 , 5861.375 , 5861.3125, 5861.125 , 5861.    , 5860.875 ,\n",
       "       5860.8125, 5862.    , 5861.9375, 5861.9375, 5861.9375, 5861.9375,\n",
       "       5861.9375, 5861.9375, 5861.9375, 5861.9375, 5861.9375, 5861.9375,\n",
       "       5861.9375, 5861.9375, 5861.9375, 5861.9375, 5862.    , 5862.0625,\n",
       "       5862.1875, 5862.4375, 5862.625 , 5862.9375, 5863.25  , 5863.5   ,\n",
       "       5863.625 , 5862.125 , 5862.375 , 5862.5625, 5862.6875, 5863.0625,\n",
       "       5863.25  , 5863.5625, 5863.75  , 5864.    , 5864.25  , 5864.4375,\n",
       "       5864.6875, 5864.9375, 5865.125 , 5865.625 , 5866.125 , 5866.5625,\n",
       "       5867.4375, 5868.5625, 5869.625 , 5870.5   , 5870.9375, 5871.0625,\n",
       "       5871.3125, 5862.375 , 5862.875 , 5863.4375, 5863.9375, 5864.625 ,\n",
       "       5865.375 , 5865.9375, 5866.1875, 5866.25  , 5866.3125, 5866.5625,\n",
       "       5866.75  , 5867.3125, 5867.875 , 5868.5625, 5869.125 , 5869.6875,\n",
       "       5870.3125, 5871.    , 5872.    , 5872.75  , 5873.625 , 5874.3125,\n",
       "       5874.8125, 5862.5   , 5862.875 , 5863.125 , 5863.25  , 5863.4375,\n",
       "       5863.5625, 5863.6875, 5863.6875, 5863.6875, 5863.6875, 5863.6875,\n",
       "       5863.6875, 5863.6875, 5863.6875, 5863.6875, 5863.75  , 5863.8125,\n",
       "       5863.8125, 5863.875 , 5863.875 , 5864.    , 5864.125 , 5864.3125,\n",
       "       5864.3125, 5862.125 , 5862.375 , 5862.625 , 5862.8125, 5863.25  ,\n",
       "       5863.5   , 5864.    , 5864.5625, 5865.125 , 5865.75  , 5866.4375,\n",
       "       5867.125 , 5868.    , 5868.9375, 5869.75  , 5870.875 , 5872.1875,\n",
       "       5873.5   , 5874.6875, 5875.875 , 5877.5   , 5879.125 , 5880.4375,\n",
       "       5881.5625, 5862.375 , 5861.8125, 5861.0625, 5860.625 , 5860.375 ,\n",
       "       5860.    , 5859.4375, 5859.0625, 5858.5   , 5858.    , 5857.625 ,\n",
       "       5857.25  , 5856.875 , 5856.625 , 5856.375 , 5856.125 , 5855.875 ,\n",
       "       5855.6875, 5855.4375, 5855.375 , 5855.    , 5854.875 , 5854.6875,\n",
       "       5854.5   , 5861.8125, 5861.5   , 5861.1875, 5860.875 , 5860.4375,\n",
       "       5859.875 , 5859.375 , 5858.9375, 5858.375 , 5857.875 , 5857.5   ,\n",
       "       5857.    , 5856.625 , 5856.25  , 5855.8125, 5855.5625, 5855.5   ,\n",
       "       5855.25  , 5855.0625, 5854.75  , 5854.625 , 5854.375 , 5854.1875,\n",
       "       5854.1875, 5862.    , 5862.    , 5862.    , 5861.875 , 5861.625 ,\n",
       "       5861.5   , 5861.1875, 5860.9375, 5860.875 , 5860.5   , 5860.375 ,\n",
       "       5860.0625, 5859.75  , 5859.375 , 5859.    , 5858.625 , 5858.1875,\n",
       "       5857.9375, 5857.6875, 5857.5   , 5857.375 , 5857.25  , 5857.125 ,\n",
       "       5857.0625, 5861.625 , 5861.375 , 5860.75  , 5860.125 , 5859.5   ,\n",
       "       5858.9375, 5858.3125, 5857.75  , 5857.3125, 5856.9375, 5856.5   ,\n",
       "       5856.125 , 5855.875 , 5855.625 , 5855.4375, 5855.3125, 5855.1875,\n",
       "       5855.125 , 5855.125 , 5855.25  , 5855.375 , 5855.375 , 5855.375 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_out.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 601)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_masked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 251, 601)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/pepper/county_env3/Iowa_Wright/Iowa_Wright_2000-12_part2.csv\n"
     ]
    }
   ],
   "source": [
    "print(f'/home/ec2-user/SageMaker/pepper/county_env3/{location}/{location}_{yearmonth}_{partname}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# do masking with netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flist_raw = !aws s3 ls s3://pepper-dataset/Temp/2000/\n",
    "# flist = []\n",
    "# for f in flist_raw:\n",
    "#     f2 = f.split(' ')[-1]\n",
    "#     f3 = f'/vsis3/pepper-dataset/Temp/{f2}'\n",
    "#     flist.append(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotrans = [-125.05, 0.1, 0, 50.05, 0, -0.1]\n",
    "vlist2 = ['evabs', 'evavt', 'sp', 'sshf', 'ssrd', 'strd', 'tp']\n",
    "vlist1 = ['t2m', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n",
    "\n",
    "for year in range(2000, 2001):\n",
    "    # 获取某一年的文件\n",
    "    year_path = eval(\"f's3://pepper-dataset/Temp/{year}/'\")\n",
    "    flist_raw = !aws s3 ls $year_path\n",
    "    flist = []\n",
    "    for f in flist_raw:\n",
    "        f2 = f.split(' ')[-1]\n",
    "        if '.nc' not in f2:\n",
    "            continue\n",
    "        f3 = f'/vsis3/pepper-dataset/Temp/{year}/{f2}'\n",
    "        flist.append(f3)\n",
    "    flist.sort()\n",
    "\n",
    "    # 遍历该年的所有netcdf文件， 确定是part1还是part2\n",
    "    for ncf in flist:\n",
    "        ncfname = os.path.basename(ncf)\n",
    "        yearmonth = ncfname.split('_')[0]\n",
    "        month_int = int(yearmonth.split('-')[1])\n",
    "\n",
    "        # # 跳过已经完成的部分\n",
    "        # if year == 2000:\n",
    "        #     if month_int not in [9, 10]:\n",
    "        #         continue\n",
    "        # 所有county数据保存在 2 个大表里\n",
    "        # 每个大表都有一个 time 列表，然后每个 county 单独一个 dict\n",
    "        # 每个 county 下面每个变量是一个表\n",
    "        # all_dict1 = {'time': []}\n",
    "        # all_dict2 = {'time': []}\n",
    "        outd = {'time': []}\n",
    "        # read basic variables\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            var_all = list(ds.variables.keys())\n",
    "            file_type = 0\n",
    "            if ncf.split('_')[-1] == 'part1.nc':\n",
    "                file_type = 1\n",
    "            elif ncf.split('_')[-1] == 'part2.nc':\n",
    "                file_type = 2\n",
    "            else:\n",
    "                raise ValueError('Unknown file type')\n",
    "            if file_type == 1:\n",
    "                for v in vlist1:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part1 file. Variable not complete. Missing: {v}')\n",
    "            elif file_type == 2:\n",
    "                for v in vlist2:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part2 file. Variable not complete. Missing: {v}')\n",
    "            else:\n",
    "                raise ValueError('Error during variable completeness check')\n",
    "\n",
    "        # set variable list\n",
    "        if file_type == 1:\n",
    "            vlist = vlist1\n",
    "            # continue\n",
    "        elif file_type == 2:\n",
    "            vlist = vlist2\n",
    "\n",
    "        # 打开netcdf文件，先获取时间信息\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            timevar = ds.variables['time'][:]\n",
    "            timelist = [\n",
    "                dt.datetime(1900, 1, 1, 0, 0) + dt.timedelta(hours = int(x)) for x in timevar\n",
    "                ]\n",
    "\n",
    "            # 根据 file_type 选择添加数据到 all_dict1 还是 all_dict2\n",
    "            if file_type == 1:\n",
    "                vlist = vlist1\n",
    "            else:\n",
    "                vlist = vlist2\n",
    "            outd['time'].extend(timelist)\n",
    "            # 遍历所有变量名，获取全美的数据\n",
    "            for v in vlist:\n",
    "                with open(f'./mask_log_updated_Iowa.log','a') as fp:\n",
    "                    now_str = dt.datetime.strftime(dt.datetime.now(), '%Y%m%dT%H%M%S')\n",
    "                    fp.writelines(f'{ncf} - {v} - {now_str}\\n')\n",
    "                arr = ds.variables[v][:]   # [time, lat, lon]\n",
    "                # arr2 = cp.asarray(arr1.data)\n",
    "                # arr = cp.where(arr2 < -30000, cp.nan, arr2)\n",
    "\n",
    "                for location in mask_dict.keys():\n",
    "                    print(ncf)\n",
    "                    print(v)\n",
    "                    print(location)\n",
    "                    if location not in outd.keys():\n",
    "                        outd[location] = {}\n",
    "                    if v not in outd[location].keys():\n",
    "                        outd[location][v] = np.array([])\n",
    "                    garr1 = mask_dict[location]\n",
    "                    garr_inds = np.where(garr1 > -10)\n",
    "                    # arr_masked = garr1 * arr\n",
    "                    arr_masked = arr[:, garr_inds[0], garr_inds[1]]\n",
    "                    arr_out = np.mean(arr_masked, axis=1)\n",
    "                    # arr_out = cp.nanmean(arr_masked, axis=(1,2))\n",
    "                    # print('einsum')\n",
    "                    # arr_out = np.einsum(\"ijk,jk->ijk\", arr, garr)\n",
    "                    # arr_out = np.einsum(\"ijk->i\", arr_masked)\n",
    "                    print('saving to outd (dictionary)')\n",
    "                    outd[location][v] = np.concatenate(\n",
    "                        [outd[location][v], arr_out],\n",
    "                        axis=0\n",
    "                        )\n",
    "                    clear_output(wait=True)\n",
    "\n",
    "\n",
    "        # 每个月保存一次\n",
    "        partname = ncfname.split('_')[1].split('.')[0]\n",
    "        errlist = []\n",
    "        for location in outd.keys():\n",
    "            if location == 'time':\n",
    "                continue\n",
    "            os.makedirs(f'/home/ec2-user/SageMaker/pepper/county_env_NETCDF4/{location}', exist_ok=True)\n",
    "            try:\n",
    "                outd1 = {}\n",
    "                for key in outd[location].keys():\n",
    "                    outd1[key] = outd[location][key]# .get()\n",
    "                t2 = pd.DataFrame(outd1)\n",
    "                t2['datetime'] = outd['time']\n",
    "                t2.to_csv(\n",
    "                    f'/home/ec2-user/SageMaker/pepper/county_env_NETCDF4/{location}/{location}_{yearmonth}_{partname}.csv', \n",
    "                    index=False\n",
    "                )\n",
    "            except:\n",
    "                print(f'error with location: {location}')\n",
    "                errlist.append(location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do masking with NetCDF4 updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vsis3/pepper-dataset/era5-unzipped/2023/2023-12_part2.nc\n",
      "tp\n",
      "Ohio_Wyandot\n",
      "saving to outd (dictionary)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# 新加：初始化 boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "geotrans = [-125.05, 0.1, 0, 50.05, 0, -0.1]\n",
    "vlist2 = ['evabs', 'evavt', 'sp', 'sshf', 'ssrd', 'strd', 'tp']\n",
    "vlist1 = ['t2m', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n",
    "\n",
    "for year in range(2011, 2024):\n",
    "    year_path = f's3://pepper-dataset/era5-unzipped/{year}/'\n",
    "    flist_raw = !aws s3 ls $year_path\n",
    "    flist = []\n",
    "    for f in flist_raw:\n",
    "        f2 = f.split(' ')[-1]\n",
    "        if '.nc' not in f2:\n",
    "            continue\n",
    "        f3 = f'/vsis3/pepper-dataset/era5-unzipped/{year}/{f2}'\n",
    "        flist.append(f3)\n",
    "    flist.sort()\n",
    "\n",
    "    for ncf in flist:\n",
    "        ncfname = os.path.basename(ncf)\n",
    "        yearmonth = ncfname.split('_')[0]\n",
    "        month_int = int(yearmonth.split('-')[1])\n",
    "\n",
    "        # --- 新加：下载S3文件到本地 ---\n",
    "        bucket_name = 'pepper-dataset'\n",
    "        key_name = ncf.replace('/vsis3/pepper-dataset/', '')  # 转换成 S3 Key\n",
    "        local_ncfile = f'/tmp/{ncfname}'  # 本地保存路径\n",
    "\n",
    "        try:\n",
    "            s3.download_file(bucket_name, key_name, local_ncfile)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {key_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        outd = {'time': []}\n",
    "\n",
    "        # --- 改：用 local_ncfile 打开 ---\n",
    "        with nc.Dataset(local_ncfile, 'r') as ds:\n",
    "            var_all = list(ds.variables.keys())\n",
    "            file_type = 0\n",
    "            if ncf.split('_')[-1] == 'part1.nc':\n",
    "                file_type = 1\n",
    "            elif ncf.split('_')[-1] == 'part2.nc':\n",
    "                file_type = 2\n",
    "            else:\n",
    "                raise ValueError('Unknown file type')\n",
    "            if file_type == 1:\n",
    "                for v in vlist1:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part1 file. Variable not complete. Missing: {v}')\n",
    "            elif file_type == 2:\n",
    "                for v in vlist2:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part2 file. Variable not complete. Missing: {v}')\n",
    "            else:\n",
    "                raise ValueError('Error during variable completeness check')\n",
    "\n",
    "        if file_type == 1:\n",
    "            vlist = vlist1\n",
    "        else:\n",
    "            vlist = vlist2\n",
    "\n",
    "        with nc.Dataset(local_ncfile, 'r') as ds:\n",
    "            timevar = ds.variables['time'][:]\n",
    "            timelist = [\n",
    "                dt.datetime(1900, 1, 1, 0, 0) + dt.timedelta(hours=int(x)) for x in timevar\n",
    "            ]\n",
    "\n",
    "            outd['time'].extend(timelist)\n",
    "\n",
    "            for v in vlist:\n",
    "                with open(f'./mask_log_updated_Others.log', 'a') as fp:\n",
    "                    now_str = dt.datetime.strftime(dt.datetime.now(), '%Y%m%dT%H%M%S')\n",
    "                    fp.writelines(f'{ncf} - {v} - {now_str}\\n')\n",
    "\n",
    "                arr = ds.variables[v][:]  # [time, lat, lon]\n",
    "\n",
    "                for location in mask_dict.keys():\n",
    "                    print(ncf)\n",
    "                    print(v)\n",
    "                    print(location)\n",
    "                    if location not in outd.keys():\n",
    "                        outd[location] = {}\n",
    "                    if v not in outd[location].keys():\n",
    "                        outd[location][v] = np.array([])\n",
    "                    garr1 = mask_dict[location]\n",
    "                    garr_inds = np.where(garr1 > -10)\n",
    "                    arr_masked = arr[:, garr_inds[0], garr_inds[1]]\n",
    "                    arr_out = np.mean(arr_masked, axis=1)\n",
    "\n",
    "                    print('saving to outd (dictionary)')\n",
    "                    outd[location][v] = np.concatenate(\n",
    "                        [outd[location][v], arr_out],\n",
    "                        axis=0\n",
    "                    )\n",
    "                    clear_output(wait=True)\n",
    "\n",
    "        # --- 可选：用完后删除本地临时文件 ---\n",
    "        try:\n",
    "            os.remove(local_ncfile)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # --- 每个月保存一次 ---\n",
    "        # partname = ncfname.split('_')[1].split('.')[0]\n",
    "        # errlist = []\n",
    "        # for location in outd.keys():\n",
    "        #     if location == 'time':\n",
    "        #         continue\n",
    "        #     os.makedirs(f'/home/ec2-user/SageMaker/pepper/county_env_NETCDF4/{location}', exist_ok=True)\n",
    "        #     try:\n",
    "        #         outd1 = {}\n",
    "        #         for key in outd[location].keys():\n",
    "        #             outd1[key] = outd[location][key]\n",
    "        #         t2 = pd.DataFrame(outd1)\n",
    "        #         t2['datetime'] = outd['time']\n",
    "        #         t2.to_csv(\n",
    "        #             f'/home/ec2-user/SageMaker/pepper/county_env_NETCDF4/{location}/{location}_{yearmonth}_{partname}.csv',\n",
    "        #             index=False\n",
    "        #         )\n",
    "        #     except:\n",
    "        #         print(f'error with location: {location}')\n",
    "        #         errlist.append(location)\n",
    "\n",
    "        partname = ncfname.split('_')[1].split('.')[0]\n",
    "        errlist = []\n",
    "        for location in outd:\n",
    "            if location == 'time':\n",
    "                continue\n",
    "            os.makedirs(f'/home/ec2-user/SageMaker/pepper/county_env_NETCDF4/{location}', exist_ok=True)\n",
    "            try:\n",
    "                outd1 = {key: outd[location][key] for key in outd[location]}\n",
    "                t2 = pd.DataFrame(outd1)\n",
    "                t2['datetime'] = outd['time']\n",
    "\n",
    "                # Precision control before saving\n",
    "                for col in t2.columns:\n",
    "                    if col == 'datetime':\n",
    "                        continue\n",
    "                    if file_type == 1:\n",
    "                        if col in ['t2m', 'stl1', 'stl2', 'stl3', 'stl4']:\n",
    "                            t2[col] = t2[col].round(1)\n",
    "                        elif col in ['rsn', 'sde', 'swvl1', 'swvl2', 'swvl3', 'swvl4']:\n",
    "                            t2[col] = t2[col].round(4)\n",
    "                    elif file_type == 2:\n",
    "                        if col in ['sp', 'sshf', 'ssrd', 'strd']:\n",
    "                            t2[col] = t2[col].round(1)\n",
    "                        elif col == 'tp':\n",
    "                            t2[col] = t2[col].round(4)\n",
    "\n",
    "                t2.to_csv(\n",
    "                    f'/home/ec2-user/SageMaker/pepper/county_env_NETCDF4/{location}/{location}_{yearmonth}_{partname}.csv',\n",
    "                    index=False\n",
    "                )\n",
    "            except:\n",
    "                print(f'error with location: {location}')\n",
    "                errlist.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN7LL7U4dGFXM88cN1Xm0xL",
   "mount_file_id": "1o_wzpzbOeZ6BW1ugNEosGSo8xbCVzhVl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
