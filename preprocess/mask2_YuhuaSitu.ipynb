{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "executionInfo": {
     "elapsed": 8580,
     "status": "ok",
     "timestamp": 1717284141542,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "KUA2iplpyAro"
   },
   "source": [
    "first time in a new instance: need to install the following\n",
    "!pip install -U boto3\n",
    "!pip install -U s3fs \n",
    "!conda install geopandas --yes\n",
    "!conda install -c conda-forge netCDF4 gdal --yes\n",
    "\n",
    "# running the two pip installs separately seems to work better somehow... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1717284132963,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "7vg9yCsgxlg2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from time import time\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import geopandas as gpd\n",
    "from osgeo import osr, gdal\n",
    "gdal.UseExceptions()\n",
    "\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "# set up s3 location\n",
    "s3 = boto3.client('s3', region_name='us-east-1')  # Replace 'us-west-2' with your AWS region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# some tests. keeping them for demo. skip when running jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-16 16:46:49 2693605824 2020-01_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-01_part2.nc\n",
      "2024-06-16 16:46:49 2519825280 2020-02_part1.nc\n",
      "2024-06-16 16:46:49 1469901152 2020-02_part2.nc\n",
      "2024-06-16 16:46:49 2693605824 2020-03_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-03_part2.nc\n",
      "2024-06-16 16:46:49 2606715548 2020-04_part1.nc\n",
      "2024-06-16 16:46:49 1520587188 2020-04_part2.nc\n",
      "2024-06-16 16:46:49 2693605820 2020-05_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-05_part2.nc\n",
      "2024-06-16 16:46:49 2606715552 2020-06_part1.nc\n",
      "2024-06-16 16:46:49 1520587188 2020-06_part2.nc\n",
      "2024-06-16 16:46:49 2693605824 2020-07_part1.nc\n",
      "2024-06-16 16:46:49 1571273216 2020-07_part2.nc\n",
      "2024-06-16 16:46:49 2693605820 2020-08_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-08_part2.nc\n",
      "2024-06-16 16:46:49 2606715552 2020-09_part1.nc\n",
      "2024-06-16 16:46:49 1520587188 2020-09_part2.nc\n",
      "2024-06-16 16:46:49 2693605820 2020-10_part1.nc\n",
      "2024-06-16 16:46:49 1571273220 2020-10_part2.nc\n",
      "2024-06-16 16:46:49 2606715552 2020-11_part1.nc\n",
      "2024-06-16 16:46:49 1520587184 2020-11_part2.nc\n",
      "2024-06-16 16:46:49 2693605824 2020-12_part1.nc\n",
      "2024-06-16 16:46:49 1571273216 2020-12_part2.nc\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://pepper-dataset/era5-unzipped/2020/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/fsspec/registry.py:275: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 21)\n"
     ]
    }
   ],
   "source": [
    "test_uri = 's3://pepper-dataset/crop_data/crop_IOWA/Iowa_corn_2019.csv'\n",
    "df = pd.read_csv(test_uri)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /vsis3/pepper-dataset/county_mask_data/mask_2/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /vsis3/pepper-dataset/county_mask_data/mask_2/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7fe86d554ea0> >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdal.Open('/vsis3/pepper-dataset/county_mask_data/mask_2/Illinois_Carroll.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ds\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2469\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2028\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc'"
     ]
    }
   ],
   "source": [
    "with nc.Dataset('/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc', 'r') as ds:\n",
    "    print(ds.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\n",
      "context: <?xml^ version=\"1.0\" encoding=\"UTF-8\"?><Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>W9YWK6ZF1EAHE547</RequestId><HostId>c5QxyL3bxFX9beXR6iNr9catK++EGTnaHtAkI40THvcazckA6jRpJGCqHm9S+Qf/w+dECquOpPI=</HostId></Error>\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -78] NetCDF: Authorization failure: 's3://pepper-dataset/era5-unzipped/2020/2020-06_part1.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ds\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2469\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2028\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -78] NetCDF: Authorization failure: 's3://pepper-dataset/era5-unzipped/2020/2020-06_part1.nc'"
     ]
    }
   ],
   "source": [
    "with nc.Dataset('s3://pepper-dataset/era5-unzipped/2020/2020-06_part1.nc', 'r') as ds:\n",
    "    print(ds.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gds = gdal.Open('/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NETCDF:\"/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\":t2m', '[720x251x601] t2m (16-bit integer)'), ('NETCDF:\"/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\":rsn', '[720x251x601] rsn (16-bit integer)')]\n",
      "['t2m', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n"
     ]
    }
   ],
   "source": [
    "era_subsets = gds.GetSubDatasets()\n",
    "print(era_subsets[:2])\n",
    "varnames = [x[0].split(':')[-1] for x in era_subsets]\n",
    "print(varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gds1 = gdal.Open(era_subsets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testarr = gds1.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF:\"/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\":t2m\n",
      "t2m\n"
     ]
    }
   ],
   "source": [
    "desc = gds1.GetDescription()\n",
    "print(desc)\n",
    "print(desc.split(':')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gds1_meta = gds1.GetMetadata()\n",
    "gds1_meta.keys()\n",
    "time_set = eval(gds1_meta['NETCDF_DIM_time_VALUES'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(time_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_list = []\n",
    "for t1 in time_set:\n",
    "    t2 = dt.datetime(1900,1,1) + dt.timedelta(hours = int(t1))\n",
    "    time_list.append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 251, 601)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testarr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# prepare masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flist_raw = !aws s3 ls s3://pepper-dataset/county_mask_data/mask_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "# 所有mask文件\n",
    "pad = '2024-06-16 02:14:19      23897 '\n",
    "len(pad)\n",
    "mask_list = []\n",
    "for f in flist_raw:\n",
    "    if \"tif\" in f:\n",
    "        fname = f[31:]\n",
    "        fpath = f\"/vsis3/pepper-dataset/county_mask_data/mask_2/{fname}\"\n",
    "        mask_list.append(fpath)\n",
    "mask_list.sort()\n",
    "print(len(mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 40607,
     "status": "ok",
     "timestamp": 1717284184051,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "p1dUPA7ayICS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 遍历所有 mask 文件，获取某个county的这个变量的数据\n",
    "mask_dict = {}\n",
    "for mask_file in mask_list:\n",
    "    fname = os.path.basename(mask_file)\n",
    "    location = fname.split('.')[0]\n",
    "    mask_dict[location] = {}\n",
    "    # read mask tiff\n",
    "    gd = gdal.Open(mask_file)\n",
    "    garr = gd.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "    mask_dict[location] = garr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do masking with gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_time(gds_subset):\n",
    "    gds = gdal.Open(gds_subset)\n",
    "    gds_meta = gds.GetMetadata()\n",
    "    time_set = eval(gds_meta['NETCDF_DIM_time_VALUES'])\n",
    "    time_list = []\n",
    "    for t1 in time_set:\n",
    "        t2 = dt.datetime(1900,1,1) + dt.timedelta(hours = int(t1))\n",
    "        time_list.append(t2)\n",
    "    del gds\n",
    "    return time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# year = 2020\n",
    "# year_path = eval(\"f's3://pepper-dataset/era5-unzipped/{year}/'\")\n",
    "# year_path\n",
    "# flist_raw = !aws s3 ls $year_path\n",
    "# flist = []\n",
    "# for f in flist_raw:\n",
    "#     f2 = f.split(' ')[-1]\n",
    "#     f3 = f'/vsis3/pepper-dataset/era5-unzipped/{year}/{f2}'\n",
    "#     flist.append(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289764,
     "status": "ok",
     "timestamp": 1717298058303,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "fPILcGAzyUFS",
    "outputId": "1c16eb47-e66e-4cdb-faf3-4feb16fabd5c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vsis3/pepper-dataset/era5-unzipped/2000/2000-01_part1.nc\n",
      "stl2\n",
      "Ohio_Wyandot\n",
      "saving to outd (dictionary)\n"
     ]
    }
   ],
   "source": [
    "geotrans = [-125.05, 0.1, 0, 50.05, 0, -0.1]\n",
    "vlist2 = ['evabs', 'evavt', 'sp', 'sshf', 'ssrd', 'strd', 'tp']\n",
    "vlist1 = ['t2m', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n",
    "\n",
    "with open('./mask_log_YuhuaSitu3.log','a') as fp:\n",
    "    fp.writelines('='*10+'\\n')\n",
    "\n",
    "for year in range(2000, 2024):\n",
    "    # 获取某一年的文件\n",
    "    year_path = eval(\"f's3://pepper-dataset/era5-unzipped/{year}/'\")\n",
    "    flist_raw = !aws s3 ls $year_path\n",
    "    flist = []\n",
    "    for f in flist_raw:\n",
    "        f2 = f.split(' ')[-1]\n",
    "        if '.nc' not in f2:\n",
    "            continue\n",
    "        f3 = f'/vsis3/pepper-dataset/era5-unzipped/{year}/{f2}'\n",
    "        flist.append(f3)\n",
    "    flist.sort()\n",
    "\n",
    "    # 遍历该年的所有netcdf文件， 确定是part1还是part2\n",
    "    for ncf in flist:\n",
    "        ncfname = os.path.basename(ncf)\n",
    "        yearmonth = ncfname.split('_')[0]\n",
    "        month_int = int(yearmonth.split('-')[1])\n",
    "\n",
    "        # 跳过已经完成的部分\n",
    "        # if year == 2020:\n",
    "        #     if month_int not in [9, 10]:\n",
    "        #         continue\n",
    "        # 所有county数据保存在 2 个大表里\n",
    "        # 每个大表都有一个 time 列表，然后每个 county 单独一个 dict\n",
    "        outd = {'time': []}\n",
    "        # read basic variables\n",
    "        gds = gdal.Open(ncf) \n",
    "        gds_subsets = gds.GetSubDatasets()\n",
    "        var_dict = {}\n",
    "        var_all = []\n",
    "        for gds_ss in gds_subsets:\n",
    "            v = gds_ss[0].split(':')[-1]\n",
    "            var_all.append(v)\n",
    "            var_dict[v] = gds_ss[0]\n",
    "\n",
    "        # set variable list \n",
    "        if ncf.split('_')[-1] == 'part1.nc':\n",
    "            vlist = vlist1\n",
    "        elif ncf.split('_')[-1] == 'part2.nc':\n",
    "            vlist = vlist2\n",
    "        else:\n",
    "            raise ValueError('Unknown file type')\n",
    "\n",
    "        # 打开netcdf文件，先获取时间信息\n",
    "        timelist = get_time(var_dict[var_all[0]])\n",
    "        outd['time'].extend(timelist)\n",
    "\n",
    "        # 遍历所有变量名，获取全美的数据\n",
    "        for v in vlist:\n",
    "            with open('./mask_log_YuhuaSitu3.log','a') as fp:\n",
    "                now_str = dt.datetime.strftime(dt.datetime.now(), '%Y%m%dT%H%M%S')\n",
    "                fp.writelines(f'{ncf} - {v} - {now_str}\\n')\n",
    "\n",
    "            gds = gdal.Open(var_dict[v])\n",
    "            arr = gds.ReadAsArray()\n",
    "\n",
    "            # arr = ds.variables[v][:]   # [time, lat, lon]\n",
    "            # arr2 = cp.asarray(arr1.data)\n",
    "            # arr = cp.where(arr2 < -30000, cp.nan, arr2)\n",
    "\n",
    "            for location in mask_dict.keys():\n",
    "                print(ncf)\n",
    "                print(v)\n",
    "                print(location)\n",
    "                if location not in outd.keys():\n",
    "                    outd[location] = {}\n",
    "                if v not in outd[location].keys():\n",
    "                    outd[location][v] = np.array([])\n",
    "                garr1 = mask_dict[location]\n",
    "                garr_inds = np.where(garr1 > -10)\n",
    "                # arr_masked = garr1 * arr\n",
    "                arr_masked = arr[:, garr_inds[0], garr_inds[1]]\n",
    "                arr_out = np.mean(arr_masked, axis=1)\n",
    "                # arr_out = cp.nanmean(arr_masked, axis=(1,2))\n",
    "                # print('einsum')\n",
    "                # arr_out = np.einsum(\"ijk,jk->ijk\", arr, garr)\n",
    "                # arr_out = np.einsum(\"ijk->i\", arr_masked)\n",
    "                print('saving to outd (dictionary)')\n",
    "                outd[location][v] = np.concatenate(\n",
    "                    [outd[location][v], arr_out],\n",
    "                    axis=0\n",
    "                    )\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        # 每个月保存一次\n",
    "        partname = ncfname.split('_')[1].split('.')[0]\n",
    "        errlist = []\n",
    "        for location in outd.keys():\n",
    "            if location == 'time':\n",
    "                continue\n",
    "            os.makedirs(f'/home/ec2-user/SageMaker/pepper/county_env3/{location}', exist_ok=True)\n",
    "            try:\n",
    "                outd1 = {}\n",
    "                for key in outd[location].keys():\n",
    "                    outd1[key] = outd[location][key]# .get()\n",
    "                t2 = pd.DataFrame(outd1)\n",
    "                t2['datetime'] = outd['time']\n",
    "                t2.to_csv(\n",
    "                    f'/home/ec2-user/SageMaker/pepper/county_env3/{location}/{location}_{yearmonth}_{partname}.csv', \n",
    "                    index=False\n",
    "                )\n",
    "            except:\n",
    "                print(f'error with location: {location}')\n",
    "                errlist.append(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'/home/ec2-user/SageMaker/pepper/county_env3/{location}/{location}_{yearmonth}_{partname}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# do masking with netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtSGtlMc4YsU"
   },
   "outputs": [],
   "source": [
    "flist_raw = !aws s3 ls s3://pepper-dataset/era5-unzipped/2020/\n",
    "flist = []\n",
    "for f in flist_raw:\n",
    "    f2 = f.split(' ')[-1]\n",
    "    f3 = f'/vsis3/pepper-dataset/era5-unzipped/{f2}'\n",
    "    flist.append(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotrans = [-125.05, 0.1, 0, 50.05, 0, -0.1]\n",
    "vlist2 = ['evabs', 'evavt', 'sp', 'sshf', 'ssrd', 'strd', 'tp']\n",
    "vlist1 = ['t2m', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n",
    "\n",
    "for year in range(2020, 2021):\n",
    "    # 获取某一年的文件\n",
    "    flist = glob(f'/content/drive/MyDrive/2024/ai_pepper/era5/unzip/{year}/*')\n",
    "    flist.sort()\n",
    "\n",
    "    # 遍历该年的所有netcdf文件， 确定是part1还是part2\n",
    "    for ncf in flist:\n",
    "        ncfname = os.path.basename(ncf)\n",
    "        yearmonth = ncfname.split('_')[0]\n",
    "        month_int = int(yearmonth.split('-')[1])\n",
    "\n",
    "        # 跳过已经完成的部分\n",
    "        if year == 2020:\n",
    "            if month_int not in [9, 10]:\n",
    "                continue\n",
    "        # 所有county数据保存在 2 个大表里\n",
    "        # 每个大表都有一个 time 列表，然后每个 county 单独一个 dict\n",
    "        # 每个 county 下面每个变量是一个表\n",
    "        # all_dict1 = {'time': []}\n",
    "        # all_dict2 = {'time': []}\n",
    "        outd = {'time': []}\n",
    "        # read basic variables\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            var_all = list(ds.variables.keys())\n",
    "            file_type = 0\n",
    "            if ncf.split('_')[-1] == 'part1.nc':\n",
    "                file_type = 1\n",
    "            elif ncf.split('_')[-1] == 'part2.nc':\n",
    "                file_type = 2\n",
    "            else:\n",
    "                raise ValueError('Unknown file type')\n",
    "            if file_type == 1:\n",
    "                for v in vlist1:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part1 file. Variable not complete. Missing: {v}')\n",
    "            elif file_type == 2:\n",
    "                for v in vlist2:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part2 file. Variable not complete. Missing: {v}')\n",
    "            else:\n",
    "                raise ValueError('Error during variable completeness check')\n",
    "\n",
    "        # set variable list\n",
    "        if file_type == 1:\n",
    "            vlist = vlist1\n",
    "            # continue\n",
    "        elif file_type == 2:\n",
    "            vlist = vlist2\n",
    "\n",
    "        # 打开netcdf文件，先获取时间信息\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            timevar = ds.variables['time'][:]\n",
    "            timelist = [\n",
    "                dt.datetime(1900, 1, 1, 0, 0) + dt.timedelta(hours = int(x)) for x in timevar\n",
    "                ]\n",
    "\n",
    "            # 根据 file_type 选择添加数据到 all_dict1 还是 all_dict2\n",
    "            if file_type == 1:\n",
    "                vlist = vlist1\n",
    "            else:\n",
    "                vlist = vlist2\n",
    "            outd['time'].extend(timelist)\n",
    "            # 遍历所有变量名，获取全美的数据\n",
    "            for v in vlist:\n",
    "                with open(f'/content/drive/MyDrive/2024/ai_pepper/era5/mask2_log_YuhuaSitu2.log','a') as fp:\n",
    "                    now_str = dt.datetime.strftime(dt.datetime.now(), '%Y%m%dT%H%M%S')\n",
    "                    fp.writelines(f'{ncf} - {v} - {now_str}\\n')\n",
    "                arr = ds.variables[v][:]   # [time, lat, lon]\n",
    "                # arr2 = cp.asarray(arr1.data)\n",
    "                # arr = cp.where(arr2 < -30000, cp.nan, arr2)\n",
    "\n",
    "                for location in mask_dict.keys():\n",
    "                    print(ncf)\n",
    "                    print(v)\n",
    "                    print(location)\n",
    "                    if location not in outd.keys():\n",
    "                        outd[location] = {}\n",
    "                    if v not in outd[location].keys():\n",
    "                        outd[location][v] = np.array([])\n",
    "                    garr1 = mask_dict[location]\n",
    "                    garr_inds = np.where(garr1 > -10)\n",
    "                    # arr_masked = garr1 * arr\n",
    "                    arr_masked = arr[:, garr_inds[0], garr_inds[1]]\n",
    "                    arr_out = np.mean(arr_masked, axis=1)\n",
    "                    # arr_out = cp.nanmean(arr_masked, axis=(1,2))\n",
    "                    # print('einsum')\n",
    "                    # arr_out = np.einsum(\"ijk,jk->ijk\", arr, garr)\n",
    "                    # arr_out = np.einsum(\"ijk->i\", arr_masked)\n",
    "                    print('saving to outd (dictionary)')\n",
    "                    outd[location][v] = np.concatenate(\n",
    "                        [outd[location][v], arr_out],\n",
    "                        axis=0\n",
    "                        )\n",
    "                    clear_output(wait=True)\n",
    "\n",
    "\n",
    "        # 每个月保存一次\n",
    "        partname = ncfname.split('_')[1].split('.')[0]\n",
    "        errlist = []\n",
    "        for location in outd.keys():\n",
    "            if location == 'time':\n",
    "                continue\n",
    "            os.makedirs(f'/content/drive/MyDrive/2024/ai_pepper/era5/county_env2/{location}', exist_ok=True)\n",
    "            try:\n",
    "                outd1 = {}\n",
    "                for key in outd[location].keys():\n",
    "                    outd1[key] = outd[location][key]# .get()\n",
    "                t2 = pd.DataFrame(outd1)\n",
    "                t2['datetime'] = outd['time']\n",
    "                t2.to_csv(f'/content/drive/MyDrive/2024/ai_pepper/era5/county_env2/{location}/{location}_{yearmonth}_{partname}.csv', index=False)\n",
    "            except:\n",
    "                print(f'error with location: {location}')\n",
    "                errlist.append(location)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN7LL7U4dGFXM88cN1Xm0xL",
   "mount_file_id": "1o_wzpzbOeZ6BW1ugNEosGSo8xbCVzhVl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
