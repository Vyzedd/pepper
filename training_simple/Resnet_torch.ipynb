{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.model_selection._split.check_cv(cv=5, y=None, *, classifier=False)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.model_selection.check_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Feature Shape: (924, 87312)\n",
      "Data Label Shape: (924, 1)\n",
      "(924, 87312)\n",
      "(1, 924)\n",
      "(305, 87312)\n",
      "(924, 1)\n",
      "(619, 87312)\n"
     ]
    }
   ],
   "source": [
    "data_feature = pd.read_csv('D:/data/crop_ai/ILLINOIS_data_feature_expanded_CORN.csv')\n",
    "data_label = pd.read_csv('D:/data/crop_ai/ILLINOIS_data_label_expanded_CORN.csv')\n",
    "\n",
    "print('Data Feature Shape:',data_feature.shape) # Verify Shape\n",
    "print('Data Label Shape:',data_label.shape) # Verify Shape\n",
    "\n",
    "train_X = data_feature\n",
    "train_y = data_label.T\n",
    "\n",
    "train_X = np.nan_to_num(train_X)\n",
    "train_y = np.nan_to_num(train_y)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "x = np.asarray(train_X, dtype=np.float32)\n",
    "y = np.asarray(train_y).flatten()\n",
    "\n",
    "# Training/Validation split 67%, 33% split\n",
    "data_feature, X_test, y_train, y_test = sk.model_selection.train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "print(X_test.shape)\n",
    "print(data_label.shape)\n",
    "print(data_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87302</th>\n",
       "      <th>87303</th>\n",
       "      <th>87304</th>\n",
       "      <th>87305</th>\n",
       "      <th>87306</th>\n",
       "      <th>87307</th>\n",
       "      <th>87308</th>\n",
       "      <th>87309</th>\n",
       "      <th>87310</th>\n",
       "      <th>87311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1893.571429</td>\n",
       "      <td>830.095238</td>\n",
       "      <td>-640.714286</td>\n",
       "      <td>-1203.380952</td>\n",
       "      <td>-1524.333333</td>\n",
       "      <td>-1938.095238</td>\n",
       "      <td>-2273.190476</td>\n",
       "      <td>-2129.523810</td>\n",
       "      <td>-2538.761905</td>\n",
       "      <td>-2763.904762</td>\n",
       "      <td>...</td>\n",
       "      <td>-32738.238095</td>\n",
       "      <td>-32738.095238</td>\n",
       "      <td>-32737.285714</td>\n",
       "      <td>-32736.619048</td>\n",
       "      <td>-32736.619048</td>\n",
       "      <td>-32736.619048</td>\n",
       "      <td>-32736.285714</td>\n",
       "      <td>-32735.714286</td>\n",
       "      <td>-32735.714286</td>\n",
       "      <td>-32735.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5037.714286</td>\n",
       "      <td>2290.571429</td>\n",
       "      <td>1840.238095</td>\n",
       "      <td>1567.809524</td>\n",
       "      <td>1436.047619</td>\n",
       "      <td>1306.714286</td>\n",
       "      <td>1322.857143</td>\n",
       "      <td>2277.904762</td>\n",
       "      <td>1996.952381</td>\n",
       "      <td>1959.380952</td>\n",
       "      <td>...</td>\n",
       "      <td>-32765.000000</td>\n",
       "      <td>-32765.000000</td>\n",
       "      <td>-32765.000000</td>\n",
       "      <td>-32765.000000</td>\n",
       "      <td>-32765.000000</td>\n",
       "      <td>-32765.000000</td>\n",
       "      <td>-32765.000000</td>\n",
       "      <td>-32765.000000</td>\n",
       "      <td>-32765.000000</td>\n",
       "      <td>-32765.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4286.238095</td>\n",
       "      <td>2491.809524</td>\n",
       "      <td>351.380952</td>\n",
       "      <td>-1746.095238</td>\n",
       "      <td>-2871.238095</td>\n",
       "      <td>-3344.000000</td>\n",
       "      <td>-3540.000000</td>\n",
       "      <td>-3955.142857</td>\n",
       "      <td>-3930.571429</td>\n",
       "      <td>-3837.619048</td>\n",
       "      <td>...</td>\n",
       "      <td>-32635.904762</td>\n",
       "      <td>-32586.142857</td>\n",
       "      <td>-32542.952381</td>\n",
       "      <td>-32506.238095</td>\n",
       "      <td>-32456.285714</td>\n",
       "      <td>-32409.428571</td>\n",
       "      <td>-32335.714286</td>\n",
       "      <td>-32175.238095</td>\n",
       "      <td>-31976.333333</td>\n",
       "      <td>-31766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-945.047619</td>\n",
       "      <td>-2167.952381</td>\n",
       "      <td>-3301.095238</td>\n",
       "      <td>-4338.190476</td>\n",
       "      <td>-5225.333333</td>\n",
       "      <td>-5914.142857</td>\n",
       "      <td>-6538.523810</td>\n",
       "      <td>-7752.380952</td>\n",
       "      <td>-8355.000000</td>\n",
       "      <td>-8738.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>-32758.523810</td>\n",
       "      <td>-32758.523810</td>\n",
       "      <td>-32758.523810</td>\n",
       "      <td>-32758.523810</td>\n",
       "      <td>-32758.523810</td>\n",
       "      <td>-32758.523810</td>\n",
       "      <td>-32758.523810</td>\n",
       "      <td>-32758.523810</td>\n",
       "      <td>-32758.523810</td>\n",
       "      <td>-32757.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3246.904762</td>\n",
       "      <td>2738.380952</td>\n",
       "      <td>1847.523810</td>\n",
       "      <td>1301.380952</td>\n",
       "      <td>1021.714286</td>\n",
       "      <td>849.714286</td>\n",
       "      <td>867.857143</td>\n",
       "      <td>663.238095</td>\n",
       "      <td>582.809524</td>\n",
       "      <td>721.095238</td>\n",
       "      <td>...</td>\n",
       "      <td>-29825.904762</td>\n",
       "      <td>-29741.619048</td>\n",
       "      <td>-29664.619048</td>\n",
       "      <td>-29592.476190</td>\n",
       "      <td>-29540.761905</td>\n",
       "      <td>-29538.761905</td>\n",
       "      <td>-29533.952381</td>\n",
       "      <td>-29531.761905</td>\n",
       "      <td>-29531.714286</td>\n",
       "      <td>-29531.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2            3            4  \\\n",
       "0  1893.571429   830.095238  -640.714286 -1203.380952 -1524.333333   \n",
       "1  5037.714286  2290.571429  1840.238095  1567.809524  1436.047619   \n",
       "2  4286.238095  2491.809524   351.380952 -1746.095238 -2871.238095   \n",
       "3  -945.047619 -2167.952381 -3301.095238 -4338.190476 -5225.333333   \n",
       "4  3246.904762  2738.380952  1847.523810  1301.380952  1021.714286   \n",
       "\n",
       "             5            6            7            8            9  ...  \\\n",
       "0 -1938.095238 -2273.190476 -2129.523810 -2538.761905 -2763.904762  ...   \n",
       "1  1306.714286  1322.857143  2277.904762  1996.952381  1959.380952  ...   \n",
       "2 -3344.000000 -3540.000000 -3955.142857 -3930.571429 -3837.619048  ...   \n",
       "3 -5914.142857 -6538.523810 -7752.380952 -8355.000000 -8738.428571  ...   \n",
       "4   849.714286   867.857143   663.238095   582.809524   721.095238  ...   \n",
       "\n",
       "          87302         87303         87304         87305         87306  \\\n",
       "0 -32738.238095 -32738.095238 -32737.285714 -32736.619048 -32736.619048   \n",
       "1 -32765.000000 -32765.000000 -32765.000000 -32765.000000 -32765.000000   \n",
       "2 -32635.904762 -32586.142857 -32542.952381 -32506.238095 -32456.285714   \n",
       "3 -32758.523810 -32758.523810 -32758.523810 -32758.523810 -32758.523810   \n",
       "4 -29825.904762 -29741.619048 -29664.619048 -29592.476190 -29540.761905   \n",
       "\n",
       "          87307         87308         87309         87310         87311  \n",
       "0 -32736.619048 -32736.285714 -32735.714286 -32735.714286 -32735.714286  \n",
       "1 -32765.000000 -32765.000000 -32765.000000 -32765.000000 -32765.000000  \n",
       "2 -32409.428571 -32335.714286 -32175.238095 -31976.333333 -31766.000000  \n",
       "3 -32758.523810 -32758.523810 -32758.523810 -32758.523810 -32757.904762  \n",
       "4 -29538.761905 -29533.952381 -29531.761905 -29531.714286 -29531.571429  \n",
       "\n",
       "[5 rows x 87312 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.read_csv('D:/data/crop_ai/ILLINOIS_data_feature_expanded_CORN.csv')\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape 训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619, 87312)\n",
      "(619, 5457, 16)\n",
      "(305, 87312)\n",
      "(305, 5457, 16)\n"
     ]
    }
   ],
   "source": [
    "def dataReshape(dataIn,debug=True,runOnce=False):\n",
    "  \"\"\"Takes the 1D feature array and reshapes to 270x16\"\"\"\n",
    "  print(dataIn.shape)\n",
    "\n",
    "  dataOut = []\n",
    "  for idx in range(len(dataIn)):\n",
    "    dataTemp = dataIn[idx].reshape(5457, 16) #(216,15) 3240\n",
    "    if debug: print(dataTemp.shape)\n",
    "    dataOut.append(dataTemp)\n",
    "\n",
    "    if runOnce: return -1\n",
    "\n",
    "  return np.array(dataOut)\n",
    "\n",
    "data_feature_rs = dataReshape(data_feature,debug=False,runOnce=False)\n",
    "print(data_feature_rs.shape)\n",
    "\n",
    "#Reshape test\n",
    "X_test = dataReshape(X_test,debug=False,runOnce=False)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转化为 torch 数据集，设置训练超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. StandardScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 数据标准化\u001b[39;00m\n\u001b[0;32m      9\u001b[0m scaler \u001b[38;5;241m=\u001b[39m sk\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mStandardScaler()\n\u001b[1;32m---> 10\u001b[0m data_feature_norm \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(data_feature_rs)\n\u001b[0;32m     11\u001b[0m X_test_norm \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 转换为 PyTorch 张量\u001b[39;00m\n",
      "File \u001b[1;32md:\\APP\\conda\\envs\\torch\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32md:\\APP\\conda\\envs\\torch\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32md:\\APP\\conda\\envs\\torch\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32md:\\APP\\conda\\envs\\torch\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\APP\\conda\\envs\\torch\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    915\u001b[0m     X,\n\u001b[0;32m    916\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    917\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    918\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    919\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[0;32m    920\u001b[0m )\n\u001b[0;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\APP\\conda\\envs\\torch\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32md:\\APP\\conda\\envs\\torch\\Lib\\site-packages\\sklearn\\utils\\validation.py:1058\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m   1064\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1065\u001b[0m         array,\n\u001b[0;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1069\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. StandardScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 网络参数\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 200\n",
    "SHUFFLE_BUFFER_SIZE = 64\n",
    "\n",
    "# 数据标准化\n",
    "scaler = sk.preprocessing.StandardScaler()\n",
    "data_feature_norm = scaler.fit_transform(data_feature_rs)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "data_feature_norm = torch.tensor(data_feature_norm, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.T, dtype=torch.float32)\n",
    "X_test_norm = torch.tensor(X_test_norm, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.T, dtype=torch.float32)\n",
    "\n",
    "# 创建 PyTorch 数据集\n",
    "train_dataset = TensorDataset(data_feature_norm, y_train)\n",
    "test_dataset = TensorDataset(X_test_norm, y_test)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 数据集大小\n",
    "DATASET_SIZE = len(train_dataset)\n",
    "\n",
    "# 打印数据加载器信息\n",
    "print(f\"Train dataset size: {len(train_dataset)}, Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619, 5457, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feature_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设数据形状为 (n_samples, n_timesteps, n_features)\n",
    "n_samples, n_timesteps, n_features = data_feature_rs.shape\n",
    "\n",
    "# 初始化 StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 将数据 reshape 为 (n_samples * n_timesteps, n_features)\n",
    "data_reshaped = data_feature_rs.reshape(-1, n_features)\n",
    "\n",
    "# 标准化\n",
    "data_scaled = scaler.fit_transform(data_reshaped)\n",
    "\n",
    "# 将数据 reshape 回原始形状\n",
    "data_feature_norm = data_scaled.reshape(n_samples, n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleResNetModel, self).__init__()\n",
    "        self.input_channels = 16\n",
    "\n",
    "        # First Pathway\n",
    "        self.cnn1 = nn.Conv1d(16, 80, kernel_size=2)\n",
    "        self.dense1 = nn.Linear(80, 64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Second Pathway\n",
    "        self.cnn2 = nn.Conv1d(16, 64, kernel_size=2)\n",
    "        self.dense2 = nn.Linear(64, 64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Third Pathway\n",
    "        self.cnn3 = nn.Conv1d(16, 32, kernel_size=2)\n",
    "        self.dense3 = nn.Linear(32, 64)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Fourth Pathway\n",
    "        self.cnn4 = nn.Conv1d(16, 16, kernel_size=2)\n",
    "        self.dense4 = nn.Linear(16, 64)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 4, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input to match PyTorch's (batch_size, channels, sequence_length)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # First pathway\n",
    "        x1 = F.relu(self.cnn1(x))\n",
    "        x1 = x1.permute(0, 2, 1)  # Switch dimensions for Linear layer\n",
    "        x1 = F.relu(self.dense1(x1))\n",
    "        x1 = x1.permute(0, 2, 1)  # Switch back for pooling\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Second pathway\n",
    "        x2 = F.relu(self.cnn2(x))\n",
    "        x2 = x2.permute(0, 2, 1)\n",
    "        x2 = F.relu(self.dense2(x2))\n",
    "        x2 = x2.permute(0, 2, 1)\n",
    "        x2 = self.pool2(x2)\n",
    "\n",
    "        # Third pathway\n",
    "        x3 = F.relu(self.cnn3(x))\n",
    "        x3 = x3.permute(0, 2, 1)\n",
    "        x3 = F.relu(self.dense3(x3))\n",
    "        x3 = x3.permute(0, 2, 1)\n",
    "        x3 = self.pool3(x3)\n",
    "\n",
    "        # Fourth pathway\n",
    "        x4 = F.relu(self.cnn4(x))\n",
    "        x4 = x4.permute(0, 2, 1)\n",
    "        x4 = F.relu(self.dense4(x4))\n",
    "        x4 = x4.permute(0, 2, 1)\n",
    "        x4 = self.pool4(x4)\n",
    "\n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleResNetModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, filters, kernel_size=2):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(filters, filters, kernel_size=kernel_size, padding='same')\n",
    "        self.bn1 = nn.BatchNorm1d(filters)\n",
    "        self.conv2 = nn.Conv1d(filters, filters, kernel_size=kernel_size, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(filters)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.input_channels = 16\n",
    "\n",
    "        # First ResNet Pathway\n",
    "        self.cnn1 = nn.Conv1d(16, 80, kernel_size=2, padding='same')\n",
    "        self.res1 = ResidualBlock(80)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Second ResNet Pathway\n",
    "        self.cnn2 = nn.Conv1d(16, 64, kernel_size=2, padding='same')\n",
    "        self.res2 = ResidualBlock(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Third ResNet Pathway\n",
    "        self.cnn3 = nn.Conv1d(16, 32, kernel_size=2, padding='same')\n",
    "        self.res3 = ResidualBlock(32)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Fourth ResNet Pathway\n",
    "        self.cnn4 = nn.Conv1d(16, 16, kernel_size=2, padding='same')\n",
    "        self.res4 = ResidualBlock(16)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(80 + 64 + 32 + 16, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input to match PyTorch's (batch_size, channels, sequence_length)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # First pathway\n",
    "        x1 = F.relu(self.cnn1(x))\n",
    "        x1 = self.res1(x1)\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Second pathway\n",
    "        x2 = F.relu(self.cnn2(x))\n",
    "        x2 = self.res2(x2)\n",
    "        x2 = self.pool2(x2)\n",
    "\n",
    "        # Third pathway\n",
    "        x3 = F.relu(self.cnn3(x))\n",
    "        x3 = self.res3(x3)\n",
    "        x3 = self.pool3(x3)\n",
    "\n",
    "        # Fourth pathway\n",
    "        x4 = F.relu(self.cnn4(x))\n",
    "        x4 = self.res4(x4)\n",
    "        x4 = self.pool4(x4)\n",
    "\n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = ResNetModel()\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
