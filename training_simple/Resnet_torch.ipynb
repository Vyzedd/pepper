{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleResNetModel, self).__init__()\n",
    "        self.input_channels = 16\n",
    "\n",
    "        # First Pathway\n",
    "        self.cnn1 = nn.Conv1d(16, 80, kernel_size=2)\n",
    "        self.dense1 = nn.Linear(80, 64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Second Pathway\n",
    "        self.cnn2 = nn.Conv1d(16, 64, kernel_size=2)\n",
    "        self.dense2 = nn.Linear(64, 64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Third Pathway\n",
    "        self.cnn3 = nn.Conv1d(16, 32, kernel_size=2)\n",
    "        self.dense3 = nn.Linear(32, 64)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Fourth Pathway\n",
    "        self.cnn4 = nn.Conv1d(16, 16, kernel_size=2)\n",
    "        self.dense4 = nn.Linear(16, 64)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 4, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input to match PyTorch's (batch_size, channels, sequence_length)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # First pathway\n",
    "        x1 = F.relu(self.cnn1(x))\n",
    "        x1 = x1.permute(0, 2, 1)  # Switch dimensions for Linear layer\n",
    "        x1 = F.relu(self.dense1(x1))\n",
    "        x1 = x1.permute(0, 2, 1)  # Switch back for pooling\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Second pathway\n",
    "        x2 = F.relu(self.cnn2(x))\n",
    "        x2 = x2.permute(0, 2, 1)\n",
    "        x2 = F.relu(self.dense2(x2))\n",
    "        x2 = x2.permute(0, 2, 1)\n",
    "        x2 = self.pool2(x2)\n",
    "\n",
    "        # Third pathway\n",
    "        x3 = F.relu(self.cnn3(x))\n",
    "        x3 = x3.permute(0, 2, 1)\n",
    "        x3 = F.relu(self.dense3(x3))\n",
    "        x3 = x3.permute(0, 2, 1)\n",
    "        x3 = self.pool3(x3)\n",
    "\n",
    "        # Fourth pathway\n",
    "        x4 = F.relu(self.cnn4(x))\n",
    "        x4 = x4.permute(0, 2, 1)\n",
    "        x4 = F.relu(self.dense4(x4))\n",
    "        x4 = x4.permute(0, 2, 1)\n",
    "        x4 = self.pool4(x4)\n",
    "\n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleResNetModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, filters, kernel_size=2):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(filters, filters, kernel_size=kernel_size, padding='same')\n",
    "        self.bn1 = nn.BatchNorm1d(filters)\n",
    "        self.conv2 = nn.Conv1d(filters, filters, kernel_size=kernel_size, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(filters)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.input_channels = 16\n",
    "\n",
    "        # First ResNet Pathway\n",
    "        self.cnn1 = nn.Conv1d(16, 80, kernel_size=2, padding='same')\n",
    "        self.res1 = ResidualBlock(80)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Second ResNet Pathway\n",
    "        self.cnn2 = nn.Conv1d(16, 64, kernel_size=2, padding='same')\n",
    "        self.res2 = ResidualBlock(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Third ResNet Pathway\n",
    "        self.cnn3 = nn.Conv1d(16, 32, kernel_size=2, padding='same')\n",
    "        self.res3 = ResidualBlock(32)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Fourth ResNet Pathway\n",
    "        self.cnn4 = nn.Conv1d(16, 16, kernel_size=2, padding='same')\n",
    "        self.res4 = ResidualBlock(16)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=128)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(80 + 64 + 32 + 16, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input to match PyTorch's (batch_size, channels, sequence_length)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # First pathway\n",
    "        x1 = F.relu(self.cnn1(x))\n",
    "        x1 = self.res1(x1)\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Second pathway\n",
    "        x2 = F.relu(self.cnn2(x))\n",
    "        x2 = self.res2(x2)\n",
    "        x2 = self.pool2(x2)\n",
    "\n",
    "        # Third pathway\n",
    "        x3 = F.relu(self.cnn3(x))\n",
    "        x3 = self.res3(x3)\n",
    "        x3 = self.pool3(x3)\n",
    "\n",
    "        # Fourth pathway\n",
    "        x4 = F.relu(self.cnn4(x))\n",
    "        x4 = self.res4(x4)\n",
    "        x4 = self.pool4(x4)\n",
    "\n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = ResNetModel()\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
