{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "executionInfo": {
     "elapsed": 8580,
     "status": "ok",
     "timestamp": 1717284141542,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "KUA2iplpyAro"
   },
   "source": [
    "first time in a new instance: need to install the following\n",
    "!pip install -U boto3\n",
    "!pip install -U s3fs \n",
    "!conda install geopandas --yes\n",
    "!conda install -c conda-forge netCDF4 gdal --yes\n",
    "\n",
    "# running the two pip installs separately seems to work better somehow... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-0.14.4-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting fiona>=1.8.21 (from geopandas)\n",
      "  Downloading fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from geopandas) (1.22.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from geopandas) (21.3)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from geopandas) (2.2.1)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Downloading pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting shapely>=1.8.0 (from geopandas)\n",
      "  Downloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2024.2.2)\n",
      "Requirement already satisfied: click~=8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Collecting click-plugins>=1.0 (from fiona>=1.8.21->geopandas)\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting cligj>=0.5 (from fiona>=1.8.21->geopandas)\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->geopandas) (3.1.2)\n",
      "Downloading geopandas-0.14.4-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl (15.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Installing collected packages: shapely, pyproj, cligj, click-plugins, fiona, geopandas\n",
      "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.9.6 geopandas-0.14.4 pyproj-3.6.1 shapely-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1717284132963,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "7vg9yCsgxlg2",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netCDF4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#from osgeo import osr, gdal\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetCDF4\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnc\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'netCDF4'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from time import time\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# import cupy as cp\n",
    "\n",
    "import geopandas as gpd\n",
    "#from osgeo import osr, gdal\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "# set up s3 location\n",
    "s3 = boto3.client('s3', region_name='us-east-1')  # Replace 'us-west-2' with your AWS region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# some tests. keeping them for demo. skip when running jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/fsspec/registry.py:275: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 21)\n"
     ]
    }
   ],
   "source": [
    "test_uri = 's3://pepper-dataset/crop_data/crop_IOWA/Iowa_corn_2019.csv'\n",
    "df = pd.read_csv(test_uri)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /vsis3/pepper-dataset/county_mask_data/mask_2/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /vsis3/pepper-dataset/county_mask_data/mask_2/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7fe86d554ea0> >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdal.Open('/vsis3/pepper-dataset/county_mask_data/mask_2/Illinois_Carroll.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ds\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2469\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2028\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc'"
     ]
    }
   ],
   "source": [
    "with nc.Dataset('/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc', 'r') as ds:\n",
    "    print(ds.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR\n",
      "context: <?xml^ version=\"1.0\" encoding=\"UTF-8\"?><Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>A8PP052W55MZSTKX</RequestId><HostId>+BQeBhBmOMvLIQMvcHAAKWwAIVzwswTFeQC6Iye3qgPZGfUgC527kRQQkE8doLA/2Ahgp2QycjM=</HostId></Error>\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -78] NetCDF: Authorization failure: 's3://pepper-dataset/era5-unzipped/2020/2020-06_part1.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ds\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2469\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2028\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -78] NetCDF: Authorization failure: 's3://pepper-dataset/era5-unzipped/2020/2020-06_part1.nc'"
     ]
    }
   ],
   "source": [
    "with nc.Dataset('s3://pepper-dataset/era5-unzipped/2020/2020-06_part1.nc', 'r') as ds:\n",
    "    print(ds.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gds \u001b[38;5;241m=\u001b[39m \u001b[43mgdal\u001b[49m\u001b[38;5;241m.\u001b[39mOpen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdal' is not defined"
     ]
    }
   ],
   "source": [
    "gds = gdal.Open('/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NETCDF:\"/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\":t2m', '[720x251x601] t2m (16-bit integer)'), ('NETCDF:\"/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\":rsn', '[720x251x601] rsn (16-bit integer)')]\n"
     ]
    }
   ],
   "source": [
    "era_subsets = gds.GetSubDatasets()\n",
    "print(era_subsets[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gds1 = gdal.Open(era_subsets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testarr = gds1.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF:\"/vsis3/pepper-dataset/era5-unzipped/2020/2020-06_part1.nc\":t2m\n",
      "t2m\n"
     ]
    }
   ],
   "source": [
    "desc = gds1.GetDescription()\n",
    "print(desc)\n",
    "print(desc.split(':')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gds1_meta = gds1.GetMetadata()\n",
    "gds1_meta.keys()\n",
    "time_set = eval(gds1_meta['NETCDF_DIM_time_VALUES'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(time_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_list = []\n",
    "for t1 in time_set:\n",
    "    t2 = dt.datetime(1900,1,1) + dt.timedelta(hours = int(t1))\n",
    "    time_list.append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 251, 601)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testarr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# prepare masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flist_raw = !aws s3 ls s3://pepper-dataset/county_mask_data/mask_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "# 所有mask文件\n",
    "pad = '2024-06-16 02:14:19      23897 '\n",
    "len(pad)\n",
    "mask_list = []\n",
    "for f in flist_raw:\n",
    "    if \"tif\" in f:\n",
    "        fname = f[31:]\n",
    "        fpath = f\"/vsis3/pepper-dataset/county_mask_data/mask_2/{fname}\"\n",
    "        mask_list.append(fpath)\n",
    "mask_list.sort()\n",
    "print(len(mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 40607,
     "status": "ok",
     "timestamp": 1717284184051,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "p1dUPA7ayICS"
   },
   "outputs": [],
   "source": [
    "# 遍历所有 mask 文件，获取某个county的这个变量的数据\n",
    "mask_dict = {}\n",
    "for mask_file in mask_list:\n",
    "    fname = os.path.basename(mask_file)\n",
    "    location = fname.split('.')[0]\n",
    "    mask_dict[location] = {}\n",
    "    # read mask tiff\n",
    "    gd = gdal.Open(mask_file)\n",
    "    garr = gd.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "    mask_dict[location] = garr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do masking with gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flist_raw = !aws s3 ls s3://pepper-dataset/era5-unzipped/2020/\n",
    "flist = []\n",
    "for f in flist_raw:\n",
    "    f2 = f.split(' ')[-1]\n",
    "    f3 = f'/vsis3/pepper-dataset/era5-unzipped/{f2}'\n",
    "    flist.append(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289764,
     "status": "ok",
     "timestamp": 1717298058303,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "fPILcGAzyUFS",
    "outputId": "1c16eb47-e66e-4cdb-faf3-4feb16fabd5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/2024/ai_pepper/era5/unzip/2020/2020-10_part2.nc\n",
      "tp\n",
      "Iowa_Wright\n",
      "saving to outd (dictionary)\n"
     ]
    }
   ],
   "source": [
    "geotrans = [-125.05, 0.1, 0, 50.05, 0, -0.1]\n",
    "vlist2 = ['evabs', 'evavt', 'sp', 'sshf', 'ssrd', 'strd', 'tp']\n",
    "vlist1 = ['t2m', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n",
    "\n",
    "for year in range(2020, 2021):\n",
    "    # 获取某一年的文件\n",
    "    flist_raw = !aws s3 ls s3://pepper-dataset/era5-unzipped/2020/\n",
    "    flist = []\n",
    "    for f in flist_raw:\n",
    "        f2 = f.split(' ')[-1]\n",
    "        f3 = f'/vsis3/pepper-dataset/era5-unzipped/{f2}'\n",
    "        flist.append(f3)\n",
    "    flist.sort()\n",
    "\n",
    "    # 遍历该年的所有netcdf文件， 确定是part1还是part2\n",
    "    for ncf in flist:\n",
    "        ncfname = os.path.basename(ncf)\n",
    "        yearmonth = ncfname.split('_')[0]\n",
    "        month_int = int(yearmonth.split('-')[1])\n",
    "\n",
    "        # 跳过已经完成的部分\n",
    "        # if year == 2020:\n",
    "        #     if month_int not in [9, 10]:\n",
    "        #         continue\n",
    "        # 所有county数据保存在 2 个大表里\n",
    "        # 每个大表都有一个 time 列表，然后每个 county 单独一个 dict\n",
    "        outd = {'time': []}\n",
    "        # read basic variables\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            var_all = list(ds.variables.keys())\n",
    "            file_type = 0\n",
    "            if ncf.split('_')[-1] == 'part1.nc':\n",
    "                file_type = 1\n",
    "            elif ncf.split('_')[-1] == 'part2.nc':\n",
    "                file_type = 2\n",
    "            else:\n",
    "                raise ValueError('Unknown file type')\n",
    "\n",
    "        # set variable list\n",
    "        if file_type == 1:\n",
    "            vlist = vlist1\n",
    "            # continue\n",
    "        elif file_type == 2:\n",
    "            vlist = vlist2\n",
    "\n",
    "        # 打开netcdf文件，先获取时间信息\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            timevar = ds.variables['time'][:]\n",
    "            timelist = [\n",
    "                dt.datetime(1900, 1, 1, 0, 0) + dt.timedelta(hours = int(x)) for x in timevar\n",
    "                ]\n",
    "\n",
    "            # 根据 file_type 选择添加数据到 all_dict1 还是 all_dict2\n",
    "            if file_type == 1:\n",
    "                vlist = vlist1\n",
    "            else:\n",
    "                vlist = vlist2\n",
    "            outd['time'].extend(timelist)\n",
    "            # 遍历所有变量名，获取全美的数据\n",
    "            for v in vlist:\n",
    "                with open(f'/content/drive/MyDrive/2024/ai_pepper/era5/mask2_log_YuhuaSitu2.log','a') as fp:\n",
    "                    now_str = dt.datetime.strftime(dt.datetime.now(), '%Y%m%dT%H%M%S')\n",
    "                    fp.writelines(f'{ncf} - {v} - {now_str}\\n')\n",
    "                arr = ds.variables[v][:]   # [time, lat, lon]\n",
    "                # arr2 = cp.asarray(arr1.data)\n",
    "                # arr = cp.where(arr2 < -30000, cp.nan, arr2)\n",
    "\n",
    "                for location in mask_dict.keys():\n",
    "                    print(ncf)\n",
    "                    print(v)\n",
    "                    print(location)\n",
    "                    if location not in outd.keys():\n",
    "                        outd[location] = {}\n",
    "                    if v not in outd[location].keys():\n",
    "                        outd[location][v] = np.array([])\n",
    "                    garr1 = mask_dict[location]\n",
    "                    garr_inds = np.where(garr1 > -10)\n",
    "                    # arr_masked = garr1 * arr\n",
    "                    arr_masked = arr[:, garr_inds[0], garr_inds[1]]\n",
    "                    arr_out = np.mean(arr_masked, axis=1)\n",
    "                    # arr_out = cp.nanmean(arr_masked, axis=(1,2))\n",
    "                    # print('einsum')\n",
    "                    # arr_out = np.einsum(\"ijk,jk->ijk\", arr, garr)\n",
    "                    # arr_out = np.einsum(\"ijk->i\", arr_masked)\n",
    "                    print('saving to outd (dictionary)')\n",
    "                    outd[location][v] = np.concatenate(\n",
    "                        [outd[location][v], arr_out],\n",
    "                        axis=0\n",
    "                        )\n",
    "                    clear_output(wait=True)\n",
    "\n",
    "\n",
    "        # 每个月保存一次\n",
    "        partname = ncfname.split('_')[1].split('.')[0]\n",
    "        errlist = []\n",
    "        for location in outd.keys():\n",
    "            if location == 'time':\n",
    "                continue\n",
    "            os.makedirs(f'/content/drive/MyDrive/2024/ai_pepper/era5/county_env2/{location}', exist_ok=True)\n",
    "            try:\n",
    "                outd1 = {}\n",
    "                for key in outd[location].keys():\n",
    "                    outd1[key] = outd[location][key]# .get()\n",
    "                t2 = pd.DataFrame(outd1)\n",
    "                t2['datetime'] = outd['time']\n",
    "                t2.to_csv(f'/content/drive/MyDrive/2024/ai_pepper/era5/county_env2/{location}/{location}_{yearmonth}_{partname}.csv', index=False)\n",
    "            except:\n",
    "                print(f'error with location: {location}')\n",
    "                errlist.append(location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# do masking with netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtSGtlMc4YsU"
   },
   "outputs": [],
   "source": [
    "flist_raw = !aws s3 ls s3://pepper-dataset/era5-unzipped/2020/\n",
    "flist = []\n",
    "for f in flist_raw:\n",
    "    f2 = f.split(' ')[-1]\n",
    "    f3 = f'/vsis3/pepper-dataset/era5-unzipped/{f2}'\n",
    "    flist.append(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotrans = [-125.05, 0.1, 0, 50.05, 0, -0.1]\n",
    "vlist2 = ['evabs', 'evavt', 'sp', 'sshf', 'ssrd', 'strd', 'tp']\n",
    "vlist1 = ['t2m', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n",
    "\n",
    "for year in range(2020, 2021):\n",
    "    # 获取某一年的文件\n",
    "    flist = glob(f'/content/drive/MyDrive/2024/ai_pepper/era5/unzip/{year}/*')\n",
    "    flist.sort()\n",
    "\n",
    "    # 遍历该年的所有netcdf文件， 确定是part1还是part2\n",
    "    for ncf in flist:\n",
    "        ncfname = os.path.basename(ncf)\n",
    "        yearmonth = ncfname.split('_')[0]\n",
    "        month_int = int(yearmonth.split('-')[1])\n",
    "\n",
    "        # 跳过已经完成的部分\n",
    "        if year == 2020:\n",
    "            if month_int not in [9, 10]:\n",
    "                continue\n",
    "        # 所有county数据保存在 2 个大表里\n",
    "        # 每个大表都有一个 time 列表，然后每个 county 单独一个 dict\n",
    "        # 每个 county 下面每个变量是一个表\n",
    "        # all_dict1 = {'time': []}\n",
    "        # all_dict2 = {'time': []}\n",
    "        outd = {'time': []}\n",
    "        # read basic variables\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            var_all = list(ds.variables.keys())\n",
    "            file_type = 0\n",
    "            if ncf.split('_')[-1] == 'part1.nc':\n",
    "                file_type = 1\n",
    "            elif ncf.split('_')[-1] == 'part2.nc':\n",
    "                file_type = 2\n",
    "            else:\n",
    "                raise ValueError('Unknown file type')\n",
    "            if file_type == 1:\n",
    "                for v in vlist1:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part1 file. Variable not complete. Missing: {v}')\n",
    "            elif file_type == 2:\n",
    "                for v in vlist2:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part2 file. Variable not complete. Missing: {v}')\n",
    "            else:\n",
    "                raise ValueError('Error during variable completeness check')\n",
    "\n",
    "        # set variable list\n",
    "        if file_type == 1:\n",
    "            vlist = vlist1\n",
    "            # continue\n",
    "        elif file_type == 2:\n",
    "            vlist = vlist2\n",
    "\n",
    "        # 打开netcdf文件，先获取时间信息\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            timevar = ds.variables['time'][:]\n",
    "            timelist = [\n",
    "                dt.datetime(1900, 1, 1, 0, 0) + dt.timedelta(hours = int(x)) for x in timevar\n",
    "                ]\n",
    "\n",
    "            # 根据 file_type 选择添加数据到 all_dict1 还是 all_dict2\n",
    "            if file_type == 1:\n",
    "                vlist = vlist1\n",
    "            else:\n",
    "                vlist = vlist2\n",
    "            outd['time'].extend(timelist)\n",
    "            # 遍历所有变量名，获取全美的数据\n",
    "            for v in vlist:\n",
    "                with open(f'/content/drive/MyDrive/2024/ai_pepper/era5/mask2_log_YuhuaSitu2.log','a') as fp:\n",
    "                    now_str = dt.datetime.strftime(dt.datetime.now(), '%Y%m%dT%H%M%S')\n",
    "                    fp.writelines(f'{ncf} - {v} - {now_str}\\n')\n",
    "                arr = ds.variables[v][:]   # [time, lat, lon]\n",
    "                # arr2 = cp.asarray(arr1.data)\n",
    "                # arr = cp.where(arr2 < -30000, cp.nan, arr2)\n",
    "\n",
    "                for location in mask_dict.keys():\n",
    "                    print(ncf)\n",
    "                    print(v)\n",
    "                    print(location)\n",
    "                    if location not in outd.keys():\n",
    "                        outd[location] = {}\n",
    "                    if v not in outd[location].keys():\n",
    "                        outd[location][v] = np.array([])\n",
    "                    garr1 = mask_dict[location]\n",
    "                    garr_inds = np.where(garr1 > -10)\n",
    "                    # arr_masked = garr1 * arr\n",
    "                    arr_masked = arr[:, garr_inds[0], garr_inds[1]]\n",
    "                    arr_out = np.mean(arr_masked, axis=1)\n",
    "                    # arr_out = cp.nanmean(arr_masked, axis=(1,2))\n",
    "                    # print('einsum')\n",
    "                    # arr_out = np.einsum(\"ijk,jk->ijk\", arr, garr)\n",
    "                    # arr_out = np.einsum(\"ijk->i\", arr_masked)\n",
    "                    print('saving to outd (dictionary)')\n",
    "                    outd[location][v] = np.concatenate(\n",
    "                        [outd[location][v], arr_out],\n",
    "                        axis=0\n",
    "                        )\n",
    "                    clear_output(wait=True)\n",
    "\n",
    "\n",
    "        # 每个月保存一次\n",
    "        partname = ncfname.split('_')[1].split('.')[0]\n",
    "        errlist = []\n",
    "        for location in outd.keys():\n",
    "            if location == 'time':\n",
    "                continue\n",
    "            os.makedirs(f'/content/drive/MyDrive/2024/ai_pepper/era5/county_env2/{location}', exist_ok=True)\n",
    "            try:\n",
    "                outd1 = {}\n",
    "                for key in outd[location].keys():\n",
    "                    outd1[key] = outd[location][key]# .get()\n",
    "                t2 = pd.DataFrame(outd1)\n",
    "                t2['datetime'] = outd['time']\n",
    "                t2.to_csv(f'/content/drive/MyDrive/2024/ai_pepper/era5/county_env2/{location}/{location}_{yearmonth}_{partname}.csv', index=False)\n",
    "            except:\n",
    "                print(f'error with location: {location}')\n",
    "                errlist.append(location)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN7LL7U4dGFXM88cN1Xm0xL",
   "mount_file_id": "1o_wzpzbOeZ6BW1ugNEosGSo8xbCVzhVl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
