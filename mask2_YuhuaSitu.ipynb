{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1717284132963,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "7vg9yCsgxlg2"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from time import time\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://www.census.gov/library/reference/code-lists/ansi/ansi-codes-for-states.html\n",
    "from osgeo import osr, gdal\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12312312313wqeqe12312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#123123123123123123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8580,
     "status": "ok",
     "timestamp": 1717284141542,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "KUA2iplpyAro"
   },
   "outputs": [],
   "source": [
    "%%capture install_status\n",
    "pip install netCDF4 #rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1717284141542,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "-Xrc0K9ZyCYP"
   },
   "outputs": [],
   "source": [
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1907,
     "status": "ok",
     "timestamp": 1717284143446,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "xMQpS4NXyFDS",
    "outputId": "a7b62787-edc0-4516-c98a-b456c95c5fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# 所有mask文件\n",
    "mask_list = glob('/content/drive/MyDrive/2024/ai_pepper/era5/county_mask1/*.tif')\n",
    "mask_list.sort()\n",
    "print(len(mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 40607,
     "status": "ok",
     "timestamp": 1717284184051,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "p1dUPA7ayICS"
   },
   "outputs": [],
   "source": [
    "# 遍历所有 mask 文件，获取某个county的这个变量的数据\n",
    "mask_dict = {}\n",
    "for mask_file in mask_list:\n",
    "    fname = os.path.basename(mask_file)\n",
    "    location = fname.split('.')[0]\n",
    "    mask_dict[location] = {}\n",
    "    # read mask tiff\n",
    "    # print('opening mask file')\n",
    "    gd = gdal.Open(mask_file)\n",
    "    garr = gd.GetRasterBand(1).ReadAsArray()\n",
    "    # garrc = cp.asarray(garr)\n",
    "    # garr = cp.where(garrc < -9000, cp.nan, garrc)\n",
    "\n",
    "    mask_dict[location] = garr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289764,
     "status": "ok",
     "timestamp": 1717298058303,
     "user": {
      "displayName": "Yuhua Situ",
      "userId": "08664026452793101142"
     },
     "user_tz": 300
    },
    "id": "fPILcGAzyUFS",
    "outputId": "1c16eb47-e66e-4cdb-faf3-4feb16fabd5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/2024/ai_pepper/era5/unzip/2020/2020-10_part2.nc\n",
      "tp\n",
      "Iowa_Wright\n",
      "saving to outd (dictionary)\n"
     ]
    }
   ],
   "source": [
    "geotrans = [-125.05, 0.1, 0, 50.05, 0, -0.1]\n",
    "vlist2 = ['evabs', 'evavt', 'sp', 'sshf', 'ssrd', 'strd', 'tp']\n",
    "vlist1 = ['t2m', 'rsn', 'sde', 'stl1', 'stl2', 'stl3', 'stl4', 'tsn', 'swvl1', 'swvl2', 'swvl3', 'swvl4']\n",
    "\n",
    "for year in range(2020, 2021):\n",
    "    # 获取某一年的文件\n",
    "    flist = glob(f'/content/drive/MyDrive/2024/ai_pepper/era5/unzip/{year}/*')\n",
    "    flist.sort()\n",
    "\n",
    "    # 遍历该年的所有netcdf文件， 确定是part1还是part2\n",
    "    for ncf in flist:\n",
    "        ncfname = os.path.basename(ncf)\n",
    "        yearmonth = ncfname.split('_')[0]\n",
    "        month_int = int(yearmonth.split('-')[1])\n",
    "\n",
    "        # 跳过已经完成的部分\n",
    "        if year == 2020:\n",
    "            if month_int not in [9, 10]:\n",
    "                continue\n",
    "        # 所有county数据保存在 2 个大表里\n",
    "        # 每个大表都有一个 time 列表，然后每个 county 单独一个 dict\n",
    "        # 每个 county 下面每个变量是一个表\n",
    "        # all_dict1 = {'time': []}\n",
    "        # all_dict2 = {'time': []}\n",
    "        outd = {'time': []}\n",
    "        # read basic variables\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            var_all = list(ds.variables.keys())\n",
    "            file_type = 0\n",
    "            if ncf.split('_')[-1] == 'part1.nc':\n",
    "                file_type = 1\n",
    "            elif ncf.split('_')[-1] == 'part2.nc':\n",
    "                file_type = 2\n",
    "            else:\n",
    "                raise ValueError('Unknown file type')\n",
    "            if file_type == 1:\n",
    "                for v in vlist1:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part1 file. Variable not complete. Missing: {v}')\n",
    "            elif file_type == 2:\n",
    "                for v in vlist2:\n",
    "                    if v not in var_all:\n",
    "                        raise ValueError(f'Part2 file. Variable not complete. Missing: {v}')\n",
    "            else:\n",
    "                raise ValueError('Error during variable completeness check')\n",
    "\n",
    "        # set variable list\n",
    "        if file_type == 1:\n",
    "            vlist = vlist1\n",
    "            # continue\n",
    "        elif file_type == 2:\n",
    "            vlist = vlist2\n",
    "\n",
    "        # 打开netcdf文件，先获取时间信息\n",
    "        with nc.Dataset(ncf,'r') as ds:\n",
    "            timevar = ds.variables['time'][:]\n",
    "            timelist = [\n",
    "                dt.datetime(1900, 1, 1, 0, 0) + dt.timedelta(hours = int(x)) for x in timevar\n",
    "                ]\n",
    "\n",
    "            # 根据 file_type 选择添加数据到 all_dict1 还是 all_dict2\n",
    "            if file_type == 1:\n",
    "                vlist = vlist1\n",
    "            else:\n",
    "                vlist = vlist2\n",
    "            outd['time'].extend(timelist)\n",
    "            # 遍历所有变量名，获取全美的数据\n",
    "            for v in vlist:\n",
    "                with open(f'/content/drive/MyDrive/2024/ai_pepper/era5/mask2_log_YuhuaSitu2.log','a') as fp:\n",
    "                    now_str = dt.datetime.strftime(dt.datetime.now(), '%Y%m%dT%H%M%S')\n",
    "                    fp.writelines(f'{ncf} - {v} - {now_str}\\n')\n",
    "                arr = ds.variables[v][:]   # [time, lat, lon]\n",
    "                # arr2 = cp.asarray(arr1.data)\n",
    "                # arr = cp.where(arr2 < -30000, cp.nan, arr2)\n",
    "\n",
    "                for location in mask_dict.keys():\n",
    "                    print(ncf)\n",
    "                    print(v)\n",
    "                    print(location)\n",
    "                    if location not in outd.keys():\n",
    "                        outd[location] = {}\n",
    "                    if v not in outd[location].keys():\n",
    "                        outd[location][v] = np.array([])\n",
    "                    garr1 = mask_dict[location]\n",
    "                    garr_inds = np.where(garr1 > -10)\n",
    "                    # arr_masked = garr1 * arr\n",
    "                    arr_masked = arr[:, garr_inds[0], garr_inds[1]]\n",
    "                    arr_out = np.mean(arr_masked, axis=1)\n",
    "                    # arr_out = cp.nanmean(arr_masked, axis=(1,2))\n",
    "                    # print('einsum')\n",
    "                    # arr_out = np.einsum(\"ijk,jk->ijk\", arr, garr)\n",
    "                    # arr_out = np.einsum(\"ijk->i\", arr_masked)\n",
    "                    print('saving to outd (dictionary)')\n",
    "                    outd[location][v] = np.concatenate(\n",
    "                        [outd[location][v], arr_out],\n",
    "                        axis=0\n",
    "                        )\n",
    "                    clear_output(wait=True)\n",
    "\n",
    "\n",
    "        # 每个月保存一次\n",
    "        partname = ncfname.split('_')[1].split('.')[0]\n",
    "        errlist = []\n",
    "        for location in outd.keys():\n",
    "            if location == 'time':\n",
    "                continue\n",
    "            os.makedirs(f'/content/drive/MyDrive/2024/ai_pepper/era5/county_env2/{location}', exist_ok=True)\n",
    "            try:\n",
    "                outd1 = {}\n",
    "                for key in outd[location].keys():\n",
    "                    outd1[key] = outd[location][key]# .get()\n",
    "                t2 = pd.DataFrame(outd1)\n",
    "                t2['datetime'] = outd['time']\n",
    "                t2.to_csv(f'/content/drive/MyDrive/2024/ai_pepper/era5/county_env2/{location}/{location}_{yearmonth}_{partname}.csv', index=False)\n",
    "            except:\n",
    "                print(f'error with location: {location}')\n",
    "                errlist.append(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtSGtlMc4YsU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN7LL7U4dGFXM88cN1Xm0xL",
   "mount_file_id": "1o_wzpzbOeZ6BW1ugNEosGSo8xbCVzhVl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
